# FATE: Boosting the Performance of Hyper-Dimensional Computing Intelligence with Flexible Numerical DAta TypE
FATE：利用灵活数值数据类型提升超维计算智能性能
# Abstract 摘要

超维计算（Hyper-Dimensional Computing，HDC）是一种有前景的类脑学习框架，专为高效、硬件友好的计算而设计。通过利用高度并行的操作，HDC 将原始数据编码到超维空间中，从而实现高效的训练与推理。然而，用于表示高维向量所需的高数值精度，在资源受限的边缘设备上实现 HDC 时带来了挑战，主要原因是余弦相似度计算中乘法操作的计算开销巨大。另一方面，二值 HDC 虽然成本更低，但会牺牲精度。

本文从数据量化这一硬件高效的压缩技术出发，在嵌入式 FPGA 上引入稀疏性，以在成本与精度之间实现有效平衡。不同于现有工作对所有维度使用同一量化方案，我们提出了一种新方法：对表示向量的不同维度采用不同的数值数据类型。该方法受到两个因素的启发：(1) 各维度的重要性存在差异；(2) 异构 FPGA 硬件资源具有更高效利用的潜力。为此，我们提出了 FATE，一种算法/架构协同设计方案：对不重要的维度使用低精度数据类型，从而用逻辑计算替代乘法操作，充分利用 FPGA 中的查找表（Look-Up Table, LUT）资源以实现高效实现。FATE 的核心洞察是：高重要性维度需要高精度数据类型，而低重要性维度则不需要，可以在很小的硬件开销下“牺牲”其精度。此外，为了最大化资源利用率，我们设计了一种面向工作负载的混合量化方案，能够基于维度重要性差异进行灵活压缩。所提出的量化框架可以无缝集成进现有的 FPGA 实现中：低精度维度主要映射到 LUT 资源，高精度维度则映射到 DSP 资源。我们在多类应用场景中评估了 FATE；在 Kintex-7 FPGA 上经过数据类型比例优化后，相比所有维度完全使用 DSP 计算的方案，我们的设计在保证精度不降低的前提下，实现了最高 50% 的加速和 53.79% 的能耗节省。

# CCS Concepts

* Hardware  $\rightarrow$  Reconfigurable logic and FPGAs（可重构逻辑与 FPGA）；
  $\cdot$  Computing methodologies  $\rightarrow$  Bio-inspired approaches（仿生计算方法）。

# Keywords 关键词

超维计算，仿生计算，类神经形态计算，压缩，基于 FPGA 的加速

# ACM Reference Format:

Haomin Li, Fangxin Liu, Yichi Chen, Zongwu Wang, Shiyuan Huang, Ning Yang, Dongxu Lyu, and Li Jiang. 2025. FATE: Boosting the Performance of Hyper-Dimensional Computing Intelligence with Flexible Numerical DAta TypE. In Proceedings of the 52nd Annual International Symposium on Computer Architecture (ISCA '25), June 21-25, 2025, Tokyo, Japan. ACM, New York, NY, USA, 14 pages. [https://doi.org/10.1145/3695053.3731031](https://doi.org/10.1145/3695053.3731031)

# 1 Introduction 引言

深度神经网络（DNN）在图像识别、目标跟踪、文本生成等广泛应用中取得了显著进展。然而，当前的 DNN 模型在端侧推理时面临巨大挑战：一方面模型规模庞大，需要以 GB 级存储空间进行存放；另一方面推理计算量极高，往往需要达到  $10^{2}$  GFLOPs 级别的浮点运算 [40, 41]。

鉴于上述挑战，类脑计算作为一种在能效和时延要求严格场景下部署 DNN 的有前景替代方案，逐渐受到关注 [29, 30, 37, 39, 58]。其中一个重要的类脑计算范式是超维计算（Hyper-Dimensional Computing, HDC）[21, 23]，其灵感来源于人脑神经回路中的分布式表示。HDC 通过将原始数据映射并编码到维度  $\geq 1,000$  的超维空间中，并采用一组并行度极高的基本操作来实现。这一编码过程确保保留了原始数据中的大量特征。编码完成后，HDC 通过一次性训练构建关联记忆（Associative Memory, AM），并在推理阶段基于余弦相似度进行关联搜索。值得注意的是，HDC 也支持模型二值化及基于汉明距离的关联搜索，使其在边缘计算场景中极具竞争力 [28, 31, 34–36, 46, 62]。因此，HDC 已广泛应用于时间序列处理 [9, 42]、语音识别 [11]、异常检测 [57]、行为识别 [24]、文本分类 [38, 45] 以及生物信号识别 [48, 64] 等领域。

为了充分释放 HDC 模型的优势，仍需解决以下若干挑战：
(i) HDC 中关联搜索模块的计算开销较大，该模块依赖乘法运算，而乘法通常比加法和逻辑运算更昂贵。随着维度和表示精度的提升，其计算开销显著增加，从而限制了可扩展性，并阻碍其在资源受限的边缘设备上的部署。我们在嵌入式 FPGA 上对单样本推理的评估表明，当每个 HDC 模型配置为 1000 维且量化到 INT8 时（见表 1），关联搜索模块的计算成本平均为编码模块的  $3.05\times$ 。因此，降低关联搜索模块的计算开销是提升整体效率的关键。
(ii) 现有压缩技术存在局限。大多数方法将 DNN 中的策略直接迁移到 HDC，如传统剪枝 [18, 43] 和量化 [10, 17]，但往往只能获得有限的精度与速度提升；
(iii) 维度删除和冗余管理不充分。许多工作采用固定比例进行维度筛选，而不考虑各维度具体的冗余情况。这种对维度“无感知”的做法忽视了维度内以及维度间的冗余，导致在低压缩率下压缩效果有限，而在高压缩率下又显著损害精度。此外，这些方法在边缘设备上的硬件实现支持不足，尽管 HDC 模型在算法层面具有天然的高并行性，非常适合在嵌入式 FPGA 上加速。因此，如何在充分挖掘维度冗余优化空间的同时，提高计算的硬件效率，尤为关键。

本文提出 FATE，一种面向嵌入式 FPGA 平台的硬件高效、维度自适应量化框架，并结合维度级稀疏性，实现高效且精确的 HDC 推理加速。FATE 通过精细粒度的量化策略，针对不同维度使用不同数据类型，从而突破固定长度量化的局限。该方法由两个关键动机驱动：(1) 超向量中各维度的重要性存在差异；(2) 异构 FPGA 硬件资源有望被更充分利用。FATE 首先进行维度重要性分析与排序，通过识别并区分各维度的重要程度，为不同维度分配最匹配的数值数据类型，使得在保证关键维度精度的前提下实现高效压缩。该精细粒度压缩方案将稀疏性与混合量化统一起来，使 HDC 模型获得更紧凑的表示。

为充分发挥 FPGA 资源的能力，我们提出了一种高效的混合位宽 HDC 推理架构，用以支持不同维度异构量化需求。这一架构充分利用 FPGA 的灵活性，高效调度 HDC 操作。此外，我们还提出了一个面向工作负载的混合量化缩放策略，会根据目标任务的特点调整不同维度的量化缩放因子。通过使量化方案与工作负载特性相匹配，我们提高了推理精度并最大化了硬件资源利用率。

表 2 概括了 FATE 的关键特性与优势。通过采用考虑维度重要性差异的精细粒度量化方案，FATE 克服了统一量化策略的局限，实现了更精确的超向量表示以及更高效的 FPGA 资源利用。通过系统评估与实验，我们展示了 FATE 在 HDC 压缩中的可扩展性与高效性。与已有量化技术对比，我们显示 FATE 在压缩率（38.75%）、推理精度损失（低于 0.5%）以及能耗降低（53.79%）方面具有明显优势。

具体来说，本文的贡献包括：

* 提出一种新的维度重要性度量——模糊距离（dimensional fuzzing-distance），可根据维度在 HDC 模型中的重要性，为其选择合适的数据类型。
* 提出一个精细粒度压缩框架 FATE，将混合数据类型量化与稀疏性无缝融合，适用于任意规模的 HDC 模型。
* 设计了一种包含异构计算引擎和多项设计优化的新型架构，以支持混合量化方案并优化 FPGA 资源分配。
* 在嵌入式 FPGA 上搭建了 FATE 原型并进行评估，开展了广泛的设计空间探索，系统研究了资源利用、目标压缩率和推理精度之间的权衡，为实现高效 HDC 推理提供了有价值的实践指导。

本文结构安排如下：第 2 节介绍背景与设计动机；第 3 节基于维度重要性度量给出我们的混合位宽量化方案；第 4 节详细描述所提出的面向工作负载的 FPGA 架构设计；第 5 节给出实验方法与结果；第 6 节回顾相关工作；第 7 节进行总结。

# 2 Background 背景

# 2.1 Hyper-Dimensional Computing 超维计算

HDC 是一种类脑计算范式，通过在超维空间中的向量（称为超向量，hypervector）来表示和学习数据。如图 1 所示，HDC 包含三个基本模块：项记忆（Item Memory, IM）、连续项记忆（Continuous Item Memory, CIM）[48]、关联记忆（Associative Memory, AM），以及编码、训练和推理三个学习阶段。

**编码（Encoding）：**
HDC 首先通过 IM 和 CIM 将样本中的每个原子数据映射为基础超向量。IM 存储对应离散值的二值基础超向量；CIM 则存储对应连续值的基础超向量。随后，HDC 使用一组预定义的操作将这些基础超向量编码为样本超向量：(i) 捆绑（Bundling，记为  $\oplus$ ）：对多个超向量进行逐元素加和以生成单一超向量；(ii) 绑定（Binding，记为  $\otimes$ ）：对两个超向量逐元素执行 XOR；(iii) 置换（Permutation，记为  $\rho$ ）：对单个超向量执行循环移位。

通常，为将某个特征映射到超维空间，HDC 会在 IM 中查找一个超向量，在 CIM 中查找一个超向量。在一些情况下，来自 IM 的基础超向量会经过置换，用于编码位置信息。随后，将这两个超向量进行绑定以融合语义，再将特征向量中各特征导出的超向量捆绑起来，形成最终的样本超向量。

如图 2 所示，对于图像，每个像素包含 5 个（属性, 值）对，包括像素坐标和 RGB 信息。IM 将彼此正交的“属性”映射到超维空间；CIM 则将“值”映射到超维空间，其中最小值和最大值在超维空间中正交，而相邻值之间具有一定相似性。

**训练（Training）：**
在训练阶段，HDC 对同一类别样本的超维表示进行捆绑，得到并存储于 AM 中的类别超向量。为进一步提高精度，一些框架会对训练样本多次迭代训练，在每轮中像推理阶段那样进行预测 [12, 14]。对于被误分类的样本，将其对应的样本超向量从错误类别的超向量中减去，并根据真实标签加入正确类别的超向量中。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/488134e175e7a5aaccc73b1de691179b44ae9317919e70643f624f639617eb83.jpg)
(a) Encoding

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/51203c708019c3b2db5122f39cac7ea58c9478e953cddcff2b8e2f6802a28e09.jpg)
(b) Training

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/1f9420a51ddd351d68f5b7a8863e8c03cda3409490ec87e76136a1d33a5973f8.jpg)
(c) Inference
图 1：超维计算基础。(a) 编码：原始数据通过 IM 和 CIM 映射到高维空间。(b) 训练：同一类别的样本向量通过捆绑操作形成类别超向量。(c) 推理：对查询超向量与已存储类别超向量进行关联搜索得到预测结果。HV 为超向量（hypervector）的缩写。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/2948cdf20fd9de7cabd27383ba2b8a60f0d1778844676c86cbbb0b5004ec3a79.jpg)
图 2：HDC 的图像编码示例。

**推理（Inference）：**
推理阶段，HDC 在 AM 中搜索与查询超向量最相似的类别超向量，并将其对应类别作为预测结果。对于连续表示，HDC 使用余弦距离作为相似性度量；对于二值模型，则采用汉明距离。

# 2.2 HDC Model Compression HDC 模型压缩

为了优化 HDC 的能耗和性能，已有许多模型压缩技术被提出，包括降维和量化。然而，这些技术存在一定局限性：CompHD [43] 使用简单的二值正交向量进行点积以实现降维，但会带来显著精度损失。SparseHD [18] 借助维度重要性判别进行粗粒度降维，但未充分析各维度重要性差异，导致压缩不足。QuantHD [10] 采用三值量化以保留更多信息，但超维表示中的冗余可能掩盖量化带来的精度损失。此外，这些方法往往依赖迭代压缩与微调才能获得满意表现。

另一方面，诸如 FACH [17, 44, 53] 等新型量化策略通过对值进行聚类，将部分相似度计算转换为加法，从而降低乘法开销。值得注意的是，这类量化策略在逻辑上独立于全局模型压缩，因此与我们的方案是正交关系；第 5 节将进一步说明这一点。

# 2.3 Analysis and Motivation 分析与动机

表 1 的评估结果展示了在固定位宽下平衡硬件成本与精度的难度。此外，图 3 显示，无论是 INT8 HDC 还是二值 HDC 模型，都难以充分利用已有硬件资源<sup>1</sup>。具体地，INT8 HDC 几乎占满所有 DSP，却只用到不到一半的 LUT；而二值 HDC 使用少量 DSP，却略多使用一点 LUT。

在上述挑战的基础上，我们识别出两个关键机遇，可作为构建硬件友好的 HDC 自适应量化框架的基础：

* **超向量内部自适应性（Intra-Hypervector Adaptivity）：**
  通过识别每个超向量内部各维度/元素的重要性差异，可以按段选择不同数据类型。对于关键区域保持高精度，而对不重要部分采用低精度，从而提高整体压缩效率。

* **维度间自适应性（Inter-Dimensionality Adaptivity）：**
  通过分析各维度分布特性，可以为不同维度定制适配的量化方案，实现更贴合各维度特征的精细压缩，使硬件利用率更高。

基于 HDC 中逐元素操作的简单性与高并行性，我们认为精细粒度混合压缩不仅可行，而且有望带来更优性能。本文对 HDC 中超向量的维度重要性进行了深入分析，基于该分析提出一种精细粒度混合数据类型压缩框架，将维度剪枝与量化统一起来。此外，我们提出了一个面向工作负载的数据类型混合缩放策略，以充分利用这一精细粒度框架。最后，我们给出了一种灵活高效的 HDC 软硬件协同压缩设计。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/a36c0624b03d0876633b53c4bf12e7defaf1653a2e71ddf603f85dc7344b4478.jpg)
图 3：HDC 的资源利用情况。

# 3 FATE Framework

本节介绍 FATE，一种在 FPGA 上实现 HDC 推理模型时，将不同数值数据类型量化方案组合使用的全新方法。首先，我们分析各维度对 AM 中关联搜索过程的影响。然后，提出一个可自适应超向量维度分布的弹性框架，通过为不同维度选择合适数据类型来进行量化。在 FATE 中，我们在 HDC 模型量化时利用多种数据类型，带来两点优势：(1) 更优的 FPGA 资源分配；(2) 几乎可以忽略的精度损失。

# 3.1 Algorithm Overview 算法概览

如图 4 所示，FATE 的输入包括两个部分：一个训练好的 HDC 模型和压缩需求。输入模型由 IM、CIM 和 AM 组成；压缩需求则主要指定用户希望使用的各类位宽比例。

FATE 包含三个模块：维度分析模块、混合位宽对齐模块以及压缩模块。维度分析模块衡量待压缩 HDC 模型各维度之间的差异；混合位宽对齐模块根据压缩需求将模型维度与不同位宽进行匹配；压缩模块则依据对齐结果，对 HDC 模块进行压缩与重排。

# 3.2 Dimensional Analysis 维度分析

为了设计维度重要性度量方案，我们首先分析 AM 中关联搜索的过程。在关联搜索阶段，HDC 需要计算样本超向量与 AM 中  $K$  个类别超向量之间的余弦相似度，并将相似度最大者对应的类别作为预测结果。该过程可形式化为式 (1)：

$$
p r e d i c t i o n = \underset {i = 1, \dots , K} {\arg \max } C o s (\vec {S}, \vec {C} _ {i}) = \underset {i = 1, \dots , K} {\arg \max } \frac {\vec {S} \cdot \vec {C} _ {i}}{| \vec {S} | | \vec {C} _ {i} |} \tag {1}
$$

其中  $\vec{S}$  为样本超向量， $\vec{C}_i$  为第  $i$  类的类别超向量。由于我们只关心相似度之间的相对大小，因子  $\frac{1}{|\vec{S}|}$  可忽略不计；如果所有类别超向量都已归一化，则  $\frac{1}{|\vec{C_i}|}$  也可忽略。因此，余弦相似度可退化为点积。于是我们尝试将寻找最大值前的计算形式化为向量-矩阵乘法：

$$
\begin{array}{l} \arg \max  \left[ \begin{array}{c} C o s (\vec {S}, \vec {C} _ {1}) \ C o s (\vec {S}, \vec {C} _ {2}) \ \dots \ C o s (\vec {S}, \vec {C} _ {K}) \end{array} \right] = \arg \max  \left[ \begin{array}{c} \vec {C} _ {1} \ \vec {C} _ {2} \ \dots \ \vec {C} _ {K} \end{array} \right] \cdot \vec {S} \tag {2} \ = \arg \max \left[ \begin{array}{c c c c} c _ {1 1} & c _ {1 2} & \dots & c _ {1 D} \ c _ {2 1} & c _ {2 2} & \dots & c _ {2 D} \ & & \dots & \ c _ {K 1} & c _ {K 2} & \dots & c _ {K D} \end{array} \right] \left[ \begin{array}{c} s _ {1} \ s _ {2} \ \dots \ s _ {D} \end{array} \right] \ \end{array}
$$

其中  $\vec{C}*i$  为行向量， $\vec{S}$  为列向量， ${c*{i1},\ldots ,c_{iD}}$  为  $\vec{C}_i$  的各分量， ${s_1,\dots,s_D}$  为  $\vec{S}$  的各分量。

我们从“模糊维度”（fuzzing dimension）的角度分析各维度的重要性差异，即矩阵中各列之间的重要性差异。对于同一个  $\vec{S}$ ，某一列对最终预测结果的影响取决于该列各元素之间的差异。考虑一个极端情况：若某列中所有元素完全相等，则该列对最终结果没有贡献，可称为“模糊维度”。由此，我们从模糊维度的极端情形反推某列的重要性，并将“将该列所有元素变为相同值所需的最小编辑距离”作为对应维度的重要性度量，记为模糊距离（fuzzing-distance）。具体而言，对于第  $i$  维的一列元素  ${c_{1i}, c_{2i}, \ldots, c_{Ki}}$ ，记其中位数为  $\text{median}_i$ ，则该维的重要性可度量为：

$$
f _ {i} = \sum_ {j = 1} ^ {K} \left| c _ {j i} - m e d i a n _ {i} \right| \tag {3}
$$

其中  $f_{i}$  为第  $i$  维的模糊距离。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/2c6072cf120b34f83a0a6b3e9b27ffe0a0548be93f5f3463a27b92abc05ab4a3.jpg)
图 4：FATE 框架。1) 基于维度重要性度量进行分析；2) 混合位宽对齐，包括维度重排与位宽分配；3) 对 IM、CIM 和 AM 进行压缩；4) 基于混合位宽的高效关联搜索推理。

# 3.3 Mixed Bit-Width Alignment 混合位宽对齐

利用上述维度级重要性度量，我们可以通过剪枝与降低表示精度来压缩 HDC 模型。在 HDC 中，我们将这两类操作统一为“降低数据位宽”这一操作。例如，从 FP32 降到 INT8、三值、二值，甚至 INT0（其中 INT0 表示该维度被剪枝）。

首先，我们按照重要性值对 AM 中的类别向量各维度进行降序排序。排序后，最重要的维度出现在列表前端，而相对不重要的维度位于列表末尾。对于列表前端的高重要性维度，我们采用较高位宽的数据表示，比如 INT8；对于列表末尾的低重要性维度，则采用较低位宽的数据表示，如三值或二值。对齐完成后，各种数据格式所对应的维度列表将被送入压缩模块进行压缩与重排。

例如，当我们希望模型中 50% 的数据使用 INT8，30% 使用 INT4，剩余 20% 直接删除时，FATE 会将排序后的维度列表与该需求对齐：前 50% 的维度使用 INT8 表示，中间 30% 的维度使用 INT4 表示，最后 20% 的维度被剪枝。当压缩需求中包含降维时，我们用 0-bit 表示列表末尾部分维度将被删除，并把该信息下传给后续模块作为压缩指令。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/efd6dbacb0676b56236599eaa5b8c090d3a59172474894cf0b8558ce9e9820a9.jpg)
图 5：置换操作带来的问题及对应解决方案示意。

# 3.4 Fine-Grained Compression 精细粒度压缩

在完成维度分类与压缩需求对齐后，FATE 进一步对 HDC 模型进行压缩，使其适合高效推理。在实际应用中，受限于计算资源，超维度的推理往往无法一次完成；编码后的样本超向量会根据维度被切分成多个子段，再与 AM 中对应类别向量的各子段逐一进行点积。

在原始维度顺序下，常常会出现不同子段需要不同计算资源的情况，导致资源调度复杂、负载极不均衡。为此，我们对 AM 中的各维度进行重排：在已知子段维度数的前提下，使不同位宽的维度在各子段中出现得尽可能平均。这样一来，复杂的资源调度需求就可以大幅缓解，子段间的工作负载也变得更稳定。

以一个 1000 维的 HDC 模型为例，压缩需求为 50% 为 INT8，50% 为 INT4，且硬件资源仅支持每个时钟周期完成一次 100 维向量乘法。此时需要将类别向量分成 10 段，每段 100 维，依次计算。如果不做重排，某一段可能包含 80 个 INT8 元素和 20 个 INT4 元素，而另一段可能只有 10 个 INT8 和 90 个 INT4，导致负载严重不均，并对资源调度提出很高要求。重排后，每一段都包含 50 个 INT8 和 50 个 INT4 元素，负载结构统一，大大简化控制逻辑与资源分配，使执行更高效。

在完成对 AM 的处理后，我们对 IM 和 CIM 进行类似处理，以确保编码后进行关联搜索的正确性。需要注意的是，在我们的框架中，为简化量化后的计算并保证降维操作的正确性，我们避免在此流程中使用置换操作。置换通常用于编码位置信息，例如 HDC 中的 N-Gram 算法 [49]；由于我们进行的是离线降维，如果在编码阶段再进行置换操作，可能会引入比特错误。

图 5 说明了这一问题。例如，字符  $a$  对应的基础超向量初始为  $[0,1,0,1,1]$ 。在部署前，FATE 框架将第 3 维（值为 0）剪枝，IM 中存储的基础超向量变为  $[0,1,1,1]$ 。如果编码中存在  $\rho(a)$ 操作，则正确的置换结果应为：
$\rho(a) = \rho([0,1,0,1,1]) = [1,0,1,0,1]$ 。
在对正确的 5 维结果进行剪枝后， $\rho(a)$ 应为  $[1,0,0,1]$ 。然而，由于我们在存储中直接保留的是剪枝后的未置换基础向量  $[0,1,1,1]$ ，对其再进行置换得到的是  $\rho(a) = [1,0,1,1]$ ，与正确结果不一致。

为此，我们提出了一种冗余存储策略以避免置换带来的问题。对于每个基础超向量，我们预先计算其所有可能的置换结果，按 FATE 建议剪枝后存储。例如，对 N-Gram 算法且  $N = 4$ 时，每个字符  $s$ 对应的 4 个超向量  $s, \rho(s), \rho^2(s), \rho^3(s)$ 都会在剪枝后以冗余形式存储。由于 N 在 HDC 中一般不大，且基础超向量为二值，因此额外存储开销是可以接受的。这一冗余存储策略保证了编码正确性的同时，避免了复杂的在线置换操作。

# 3.5 Efficient Online Inference 高效在线推理

在 FATE 框架中，即便使用混合位宽，在线推理流程依然十分清晰（见图 4）。当一个样本输入模型后，首先经过 IM 和 CIM 的映射与编码。由于 IM 与 CIM 已经过重排，样本超向量与 AM 中的类别超向量在维度上得到对齐。在此基础上，将超向量切分为多个子段并迭代处理的计算流程中，各个阶段的工作负载相对稳定，有利于充分利用计算资源。

此外，不同位宽的量化会在逐元素乘法中引入不同的缩放因子，因此在乘法结果上需要配合适当的位移操作以保证数值正确。通过维度重排、工作负载稳定化以及正确的缩放策略，FATE 在混合位宽下仍能实现高效精确的在线推理。

# 3.6 Adjustment Mechanism 调整机制

为进一步提升性能，我们引入了一种自适应调整机制，通过多轮压缩与更新迭代提高压缩模型的精度。流程如下：(i) **压缩与存储**：首先根据给定标准对模型进行压缩，并保留一份未压缩模型副本；(ii) **推理与更新**：使用压缩模型在训练集上进行推理，识别被误分类样本，然后对原始未压缩模型按前述重训练策略进行更新；(iii) **后续轮次**：下一轮中，对上一轮更新后的未压缩模型再次执行压缩。上述过程可重复若干轮，以逐步提升压缩后的精度。

# 4 FPGA Implementation: Design and Optimization

FPGA 实现：设计与优化

我们提出的 FATE 通过组合多种数值数据类型量化方案，显著提升了 FPGA 部署效率。具体而言，FATE 以硬件友好方式利用维度间自适应特性，具有两个明显优势：(i) 对于低精度量化值（二值和三值），使用 LUT 实现乘法等效的逻辑操作以替代传统乘法器 [56]；(ii) 充分利用 FPGA 中的 DSP 与 LUT 资源：LUT 主要负责低精度计算，DSP 负责常规乘法。由此，相比受 DSP 数量限制的既有设计，FATE 能在同一 FPGA 器件上实现更高吞吐。本节将介绍支持该算法的异构引擎硬件设计。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/6942122c6e1f19c1b381a56b354b53d8c6f84c0e58624c5f77fb214b700ddb06.jpg)
图 6：FATE 架构总览。

# 4.1 Architecture Overview 架构总览

基于 FATE 框架，我们设计了对应硬件架构，为高效推理提供支持，如图 6 所示。FATE 架构包含两个主要部分：编码（encoding）与关联搜索（associative search）。编码部分负责将输入样本通过投影映射到超维空间，并将其编码为超向量用于后续处理；关联搜索部分则负责在 AM 中搜索与编码后超向量最相似的类别超向量，以完成分类。

# 4.2 Encoding Design 编码设计

如图 6 所示，编码模块主要包括三个组件：基础超向量存储器（Base Hypervector Memory）、XOR 累加阵列（XOR Accumulation Array）以及分段缓冲（Segment Buffer）。

* **Base Hypervector Memory** 用于存储从 IM 和 CIM 中提取的基础超向量。对于输入样本的每个特征维度，其对应的“特征基础超向量”和“特征值基础超向量”会被激活并读出，供 XOR 累加阵列使用。
* **XOR Accumulation Array** 对来自存储器的两个基础超向量执行逐元素 XOR，然后将结果与当前查询超向量进行逐元素加和（查询超向量初始为全 0）。
* **Segment Buffer** 则用于缓存从累加阵列输出的编码结果。由于高维数据在关联搜索部分可能需要分多次完成推理，编码结果会被切分成若干较小的查询向量（如 100 维），依次发送至关联搜索模块多轮计算，从而完成整个推理。

# 4.3 Associative Search Design 关联搜索设计

图 7 给出了关联搜索架构，其主要由三部分组成：压缩后的类别超向量存储、混合位宽乘法阵列以及加法树。

在这一部分，我们的目标是在并行度限制下，计算每个查询超向量与所有类别超向量的相似度。具体做法是在每一轮中进行元素级乘法，然后进行规约。嵌入式 FPGA 上可用 DSP 数量一般不超过 1000，类别数也通常不多，因此高位宽维度参与计算的规模相对较小，这也凸显了编码阶段分段缓存的重要性。

图 7 左侧展示了压缩后的类别超向量在 RAM 中的存储方式。当查询向量到达后，多个类别向量会并行与该查询向量进行计算，从而充分利用 HDC 的天然并行性。混合位宽存储会引入一定寻址开销，但相对于减少的乘法开销，这一点是值得的。

**混合位宽乘法阵列** 是设计核心，用于处理寻址后的类别超向量与查询超向量。为了最大化资源利用，不同位宽维度采用不同实现方式：对于 INT8，我们使用 DSP 实现乘法；对于 INT4 和三值等较低位宽，则采用 LUT 实现；对于二值计算，则由逻辑电路根据类别超向量的值决定查询超向量对应位置是保留还是清零。虽然低位宽计算使用 LUT 实现，但其 LUT 消耗会随位宽变化；压缩需求可以根据可用计算资源调整，从而控制资源利用。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/c3c52b774b839790af168701ecaabe2c78529ed9872b3435a7b0f2832b6f9574.jpg)
图 7：FATE 架构：关联搜索设计。

不同位宽乘法结果会通过位移对齐以保证正确性：INT4 结果左移 4 位，三值结果左移 6 位，二值结果左移 7 位。例如，当结果为 162（来自查询向量值 54 与类别向量中一个 INT4 值 3 的乘积）时，将左移 4 位得到 2592。由于最终的乘法结果向量已对齐且各值位宽相同，我们可用加法树高效完成求和。

# 4.4 Pipeline Design 流水线设计

为高效利用计算资源并降低推理时延，我们设计了优化的数据流。图 8(a) 展示了从原始特征数据到编码超向量的计算流程。受资源限制，编码后的超向量在 Segment Buffer 中被划分为  $D / d$  个片段，其中  $D$  为超向量维度， $d$ 为关联搜索模块中单次并行计算的最大维度数。

在关联搜索中，每轮计算一个长度为  $d$ 的片段向量  $Q_i$ ，其计算包括三步：① 混合位宽逐元素乘法；② 位移调整；③ 加法树规约。图 8(b) 展示了高效执行流程。为简化控制，我们通过插入寄存器保证不同位宽乘法器拥有统一的流水级数（实践中通常为 3 级），即当  $Q_i$ 输入关联搜索模块后，所有乘法单元在 3 个周期后输出结果。加法树模块采用  $\log(d)$  级流水结构，以高效规约该乘法结果向量。位移操作则通过在乘法结果后拼接零比特，并由加法树统一处理实现。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/ab0b56c6ee294815ccd86983e6721f5f52e27ebdb820dbc0d97aad878c9b1420.jpg)
图 8：(a) 推理数据流；(b) 推理执行时序。

# 5 Evaluation 评估

# 5.1 Experimental Setup 实验设置

**平台与基准：** 我们在软件和硬件两个层面实现并评估 FATE。在软件方面，我们用 Python 实现 FATE 框架，并在配备 16GB 内存的 Intel(R) Xeon(R) Silver 4208 CPU 上运行。在硬件方面，我们在嵌入式 FPGA 上设计具有异构计算核心的架构，特别适用于资源受限但对效率要求较高的场景。硬件实现基于 Kintex-7 FPGA，使用 Verilog 编写，工作频率设置为  $200\mathrm{MHz}$ 。我们使用 Xilinx Vivado Design Suite [4] 完成综合，并结合 Vivado 功耗估计报告和对应时延获得能耗。所用三类数据集见表 3。

Table 1: HDC inference energy consumption & latency.

<table><tr><td rowspan="2">Tasks</td><td rowspan="2">Bit-Width</td><td colspan="2">Energy Consumption (μJ)</td><td colspan="2">Latency (μs)</td><td rowspan="2">Accuracy (%)</td></tr><tr><td>Encode</td><td>Associative Search</td><td>Encode</td><td>Associative Search</td></tr><tr><td rowspan="2">Speech Recognition[3]</td><td>INT8</td><td>2.115</td><td>6.345</td><td>29.00</td><td>87.00</td><td>90.57</td></tr><tr><td>Binary</td><td>2.115</td><td>0.705</td><td>29.00</td><td>9.67</td><td>78.45</td></tr><tr><td rowspan="2">Activity Detection[51]</td><td>INT8</td><td>1.905</td><td>2.540</td><td>54.00</td><td>72.00</td><td>93.04</td></tr><tr><td>Binary</td><td>1.805</td><td>0.60</td><td>54.00</td><td>18.01</td><td>88.27</td></tr><tr><td rowspan="2">Disease Classification[1]</td><td>INT8</td><td>0.093</td><td>0.465</td><td>14.00</td><td>70.0</td><td>80.28</td></tr><tr><td>Binary</td><td>0.093</td><td>0.093</td><td>14.00</td><td>14.00</td><td>76.53</td></tr></table>

Table 2: Comparison of different compression methods.

<table><tr><td>Method</td><td>FATE</td><td>QuantHD [10]</td><td>SparseHD [18]</td><td>CompHD [43]</td></tr><tr><td>Quantization</td><td>✓</td><td>✓</td><td>×</td><td>×</td></tr><tr><td>Sparsity(Dim pruning)</td><td>✓</td><td>×</td><td>✓</td><td>✓</td></tr><tr><td>Bit-Width</td><td>Mixed</td><td>Binary+Tenary</td><td>Binary</td><td>Binary</td></tr></table>

Table 3: Dataset Statistics.

<table><tr><td>Dataset</td><td>#feature</td><td>#class</td><td>Train Size</td><td>Test Size</td><td>Description</td></tr><tr><td>ISOLET [3]</td><td>617</td><td>26</td><td>6,238</td><td>1,559</td><td>Speech recognition</td></tr><tr><td>UCIHAR [51]</td><td>561</td><td>12</td><td>6,213</td><td>1,554</td><td>Activity recognition</td></tr><tr><td>CARDIO [1]</td><td>21</td><td>10</td><td>1,913</td><td>213</td><td>Disease classification</td></tr></table>

**基线与代表性 FATE 配置：**
我们主要将 FATE 与原始 INT8 HDC 模型和二值 HDC 模型进行对比，同时也与 CompHD [43]、SparseHD [18]、QuantHD [10] 和 FACH [17] 等 SOTA 工作进行比较。SparseHD、CompHD 与 QuantHD 主要关注纯稀疏或单一位宽量化压缩。此外，我们引入五组典型位宽比例方案 FATE-1 至 FATE-5。FATE-1 为具备 50% 稀疏度的 HDC，与 SparseHD 和 CompHD 配置对齐；对于 QuantHD，我们按 [10] 的方法实现了三值 HDC。各模型的位宽比例配置见图 9(a)。所有模型均在 1000 维超向量下评估。我们还探索了不同设计参数对性能与资源利用的影响。与 [18] 一致，我们在 FPGA 和 GPU 上均实现了基线模型；相比 GPU 版本，FPGA 版本可实现约  $8\times$  的能效提升和  $2\times$  的加速<sup>2</sup>。为便于对比，以下以 FPGA 版本作为基线。

# 5.2 Overall Performance 整体性能

图 9 对比了 FATE 与各基线在精度与存储上的表现。图 9(a) 展示了不同模型的位宽比例，图 9(b) 则给出了对应的精度与存储大小。

对于 CompHD 和 SparseHD，我们选取了“二值 HDC + 半维度剪枝”的代表性配置。FATE-1 在相同配置下进行评估。结果表明：与 1k 维的二值 HDC 相比，在使用相同大小的关联记忆时，我们方法的平均精度损失小于 3.5%，而 CompHD 和 SparseHD 的平均精度损失分别达到 23.59% 和 15.93%。更详细的稀疏性分析见 5.4 节。

对 QuantHD 量化框架的评估显示，在三值 HDC 与二值 HDC 上，粗粒度低位宽量化虽能显著降低存储开销，但会带来较大精度退化——最差情况下精度损失可达 12%，难以接受。

相比之下，FATE-2 相对于 INT8 HDC 模型实现了 38.75% 的存储压缩，精度损失却低于 0.5%，更适合边缘智能场景。此外，FATE-1 和 FATE-2 相比 CompHD 与 SparseHD 最高可提升精度 35.68%。FATE-3 的位宽变化比 FATE-2 更不平滑，导致相比 INT4 HDC 模型平均精度下降约 3%，进一步体现了合理混合位宽设计对平衡压缩与精度的重要性。FATE-4 和 FATE-5 则展示了框架的灵活性：用户可以通过调整位宽比例控制精度。具体而言，FATE-4 在多消耗约 2KB 存储的前提下适用于对精度要求更高的场景，而 FATE-5 则更侧重存储压缩，允许在可接受范围内牺牲精度。这种灵活性使得用户可以面向具体部署需求选择合适的 HDC 方案。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/de1f47ccd16e478e2e993f8faa4f03abc702e76716c620c7617c2acfc15d0e7c.jpg)
图 9：不同 HDC 模型中各数据类型比例（左）与对应量化精度（右）。

图 10 对比了我们的架构与受 DSP 资源限制的 INT8 HDC 模型在关联搜索延迟上的表现。由于 CompHD 与 SparseHD 在硬件上与 FATE-1 共用实现，这两者未单独列出。得益于对低位宽乘法采用 LUT 实现，FATE 各配置的推理速度显著提升。与 INT4 或更低位宽的 HDC 模型相比，FATE 拥有相似甚至更低的推理时延，同时保证更高的关联搜索精度。具体而言，FATE-2（INT8:INT4:三值:二值  $= 4:3:2:1$ ）在精度损失低于 0.5% 的前提下，相比 INT8 HDC 可实现最高 47.14% 的时延降低。综合多种配置的评估结果可见，FATE 框架在多种边缘应用场景下具备高度灵活性，能够在满足推理时延需求的同时保持高精度，是极具实用性的一种方案。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/e4a34ae0fb52ac54aa943076fa459ce350595f95e8d0b0c3af331c92acbd9b17.jpg)
图 10：关联搜索时延。

# 5.3 Energy Efficiency 能效分析

图 11 展示了混合位宽策略下各 HDC 模型的能耗结果，凸显了我们的优势。通过在所有配置中利用 LUT 型乘法器突破 DSP 限制，FATE-2 相比 INT8 HDC 模型最高可降低 53.79% 的能耗，平均降低 17.84%。FATE-4 的平均能耗约为 INT8 模型的 78%。

能耗优势主要来自对低重要性维度采用低精度表示，从而减少高精度乘法器的使用。此外，带稀疏性的 FATE-1 相比标准二值 HDC 模型（剪枝 50% 维度）可节约平均 50% 的能量。

图 12 给出了加法树与乘法阵列的功耗分解。原始 HDC 实现中乘法开销较高，体现了 FATE 设计的重要性。FATE 的乘法部分功耗占比平均比原始 HDC 低约 10%，进一步表明其非常适合资源受限的嵌入式 FPGA 平台。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/c671143fbb53860a0b6341ccd37a3cbe6850dc02583a22600c6dfe1477586b47.jpg)
图 11：能耗对比。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/3bef4dfa77524cc28ae3ceb0d98eb2b4bbc615523996f866672d675dc9b5649e.jpg)
图 12：关联记忆部分功耗分解。

# 5.4 Sparsity Evaluation 稀疏性评估

在稀疏性与降维方面，我们与 SparseHD 和 CompHD 进行对比，结果见图 13。我们在语音与行为识别任务上，分别对 INT8 HDC 与二值 HDC 模型考察了多种稀疏率配置下的压缩效果。需要注意的是，不同稀疏率在相同精度目标下意味着不同的存储与计算开销，因为稀疏度与开销大致呈线性关系。

结果表明，随着稀疏率提升，FATE 相对其他两种方法的优势不断增大。在二值 HDC 模型压缩且稀疏率为 80% 的情况下，FATE 相比 CompHD 的精度可最高提高 32%，相比 SparseHD 提高 20%。在 INT8 HDC 模型压缩中，当稀疏率为 50% 时，FATE 的平均精度比 CompHD 高 5%，比 SparseHD 高 3%。当稀疏率为 30% 时，二值 FATE 比其他方法精度高 10% 以上，而 INT8 FATE 的精度优势超过 4%。

此外，当比较“在同等精度下谁能获得更高稀疏度”时，我们发现：在 ISOLET 数据集上，FATE 配置 90% 稀疏仍能与 CompHD 在仅 20% 稀疏率下获得近似精度（图中绿线所示）。这一显著优势归功于 FATE 能更充分地利用每一维度去区分不同类别。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/ea088c2f042112d706bd02b321e4526d83699b825aa855cbd3e19975d6f84cf2.jpg)
图 13：随稀疏率变化的模型精度。绿色折线为 FATE 在 90% 稀疏下的精度。

# 5.5 Quantization Evaluation 量化评估

如图 14(a) 所示，我们将 FATE 与 QuantHD 进行比较。为公平起见，我们仅在二值和三值位宽之间混合，因为 QuantHD 只支持将模型量化到二值或三值。图中用三值维度与二值维度的比例表示配置，“0:10” 对应二值 QuantHD，“10:0” 对应三值版本，其余比例为不同的 FATE 配置。结果表明，最高精度（图中红虚线标示）不仅可以由三值模型达到，也可以通过 FATE 的混合位宽配置实现。例如，在 HAR 数据集上，FATE 将 20% 的维度量化为二值，仍能与纯三值版本达到同等精度。这说明 FATE 在降低计算与存储开销的同时，能够匹配甚至超越现有量化框架的精度。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/5628c005b1ee589813c2e95b272450e0333d5d54579a447add6f0a05baedec43.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/327f7e879201505318d058c3e4c196aa7157829de9170811e44be6af44dada81.jpg)
图 14：量化评估。(a) QuantHD 与 FATE 对比。(b) 不同维度重要性度量下 FATE 精度表现。

为评估我们的维度重要性度量，我们与随机选择以及基于范围（range-based）的方法进行对比。我们在多个精度比例配置（FATE-Q1 至 FATE-Q6）下进行实验，结果如图 14(b)。当高位宽（int8）维度比例较高时，我们的度量方法在 HAR 与 CARDIO 数据集上相较基线优势不大，并且在 ISOLET 上略逊于 range-based 方法；但随着高位宽比例降低，我们的方法优势愈加明显。例如，在 HAR 数据集上的最佳情形中，相比 range-based 方法可提高 5% 的精度。此外，我们还注意到，在部分配置下，range-based 方法甚至不如随机选择，且在 HAR 与 CARDIO 上差距超过 2%。原因在于 range-based 方法仅刻画了维度对“任意两类”间最大区分能力，却未能反映该维度在“所有类别对”上的总区分能力，因而稳定性较差。相比之下，我们的模糊距离度量更加稳定，且在各配置中始终优于随机方法。

Table 4: Scalability Analysis.

<table><tr><td rowspan="2">Methods</td><td colspan="3">Accuracy(%)</td><td colspan="3">Multiplication Times</td></tr><tr><td>ISOLET</td><td>HAR</td><td>CARDIO</td><td>ISOLET</td><td>HAR</td><td>CARDIO</td></tr><tr><td>FATE</td><td>88.65</td><td>91.40</td><td>79.81</td><td>13000</td><td>6000</td><td>5000</td></tr><tr><td>FATE-FACH (k=256)</td><td>88.20</td><td>91.24</td><td>79.34</td><td>5059</td><td>2281</td><td>1926</td></tr><tr><td>FATE-FACH (k=128)</td><td>88.00</td><td>90.61</td><td>78.81</td><td>2987</td><td>1366</td><td>1138</td></tr><tr><td>FATE-FACH (k=64)</td><td>85.63</td><td>90.86</td><td>78.87</td><td>1623</td><td>747</td><td>607</td></tr><tr><td>FATE-FACH (k=32)</td><td>85.95</td><td>88.27</td><td>77.46</td><td>832</td><td>384</td><td>317</td></tr><tr><td>FATE-FACH (k=16)</td><td>76.27</td><td>73.37</td><td>75.11</td><td>416</td><td>192</td><td>160</td></tr></table>

# 5.6 Scalability 可扩展性

如 2.2 节所述，FATE 与某些新型 HDC 压缩方法是正交的。为展示其兼容性，我们将 FACH 框架集成到 FATE 中，形成 FATE-FACH 方案。FACH 框架通过对 AM 中的值进行聚类与量化，将属于同一量化值的维度在查询向量中先累加，再进行乘法，从而减少乘法次数。为评估该优化的收益，我们在 FATE 先将 HDC 模型压缩到 500 维（INT8）后，再应用 FACH。表 4 给出在三类数据集上不同聚类数  $k$ 下的精度与平均每次推理所需乘法次数。

当  $k=256$ 时，FATE-FACH 等价于一种非均匀 INT8 量化，精度几乎不变，但可将乘法开销减半以上。若  $k=64$ ，乘法开销可减少近 90%，平均精度损失约 1.2%；当  $k=32$ 时，乘法开销可减少近 95%，平均精度损失约 2.7%。这些结果充分表明，我们的方法可以与新兴压缩方法协同优化，以极小的代价显著减少计算开销。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/31bdc80dde5eb58cd204fd5556c7c67a8e2c0537fce52dfa62e1e2746b044450.jpg)
图 15：在不同配置下 FATE 的 FPGA 资源利用情况。

# 5.7 Resource-aware & Flexibly Deployment

面向资源的灵活部署

图 15 显示了 FATE 在 ISOLET 与 HAR 数据集上的不同配置下资源利用情况。通过混合数据类型方法，FATE 同时充分利用了 DSP 与 LUT：对低精度数据最大化 LUT 使用，对高精度数据最大化 DSP 使用，从而突破仅受 DSP 限制的既有设计。资源利用率依赖于位宽比例配置。例如，FATE-4 使用相对更少的 DSP，但更多依赖 LUT 和触发器（FF）；FATE-3 则在 LUT、FF 与 DSP 三类资源上利用率都高于 FATE-4。这种适配性使 FATE 能够针对不同边缘部署场景的资源约束灵活调整。

为更细致地分析资源利用情况，表 5 列出了 FATE 在不同配置下的资源使用量。FATE-1 完全不使用 DSP，FATE-2 只使用少量 DSP，适合 DSP 资源有限的 FPGA；FATE-3 与 FATE-4 则大量使用 LUT 与 FF，适合逻辑资源较为富余的 FPGA；FATE-5 相比 FATE-3/4 使用的逻辑资源更少，适合逻辑资源较紧张的设备。这表明，通过调整配置，FATE 能够适应不同资源分配特征的 FPGA。

Table 5: FPGA resource utilization analysis.

<table><tr><td>Workload</td><td>Resource</td><td>FATE-1</td><td>FATE-2</td><td>FATE-3</td><td>FATE-4</td><td>FATE-5</td></tr><tr><td rowspan="3">ISOLET</td><td>LUT</td><td>29,759</td><td>45,234</td><td>55,520</td><td>55,158</td><td>48,697</td></tr><tr><td>FF</td><td>50,591</td><td>45,163</td><td>71,253</td><td>61,203</td><td>39,694</td></tr><tr><td>DSP</td><td>0</td><td>260</td><td>520</td><td>468</td><td>546</td></tr><tr><td rowspan="3">HAR</td><td>LUT</td><td>18,716</td><td>27,339</td><td>36,261</td><td>35,324</td><td>32,552</td></tr><tr><td>FF</td><td>29,398</td><td>26,857</td><td>40,926</td><td>34,830</td><td>26,591</td></tr><tr><td>DSP</td><td>0</td><td>120</td><td>240</td><td>144</td><td>252</td></tr></table>

# 5.8 Performance over Vision Task 视觉任务上的性能

我们进一步在常用视觉数据集 MNIST [25] 与 Fashion MNIST [61] 上评估 FATE 的表现。如图 16 所示，在二值 HDC 实现下剪枝 50% 维度的 FATE-CV-5，可在不损失精度的前提下实现最高 20× 的加速。对于 Fashion MNIST，三值 HDC 实现虽然只需 24.41KB 的存储，但相对于 INT8 版本存在近 3% 的精度损失。相比之下，将 INT4、三值与二值数据类型混合的 FATE-CV-4 在 34.18KB 存储下实现无损压缩，相对于 INT8 HDC 实现达到了约 2.8× 的压缩率。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/f344b2f7066c10f75728dab1b483a988d030237cf7f6082976df1ab8db222dbd.jpg)
图 16：在 CV 任务中，不同数据类型比例（左）、精度（中）与加速比（右）。

# 5.9 Scalability to Larger Real-World Applications: Graph Representation Learning

面向大规模实际应用的可扩展性：图表示学习

我们还在图表示学习任务上评估 FATE，以展示其在更大规模实际应用中的可扩展性。表 6 给出了三个节点分类任务的配置：Cora 与 CiteSeer 为引文网络 [54]，NELL 为知识图谱 [2]。我们复现了 SOTA 的 HDC 模型 [27]，并与经典 GNN 模型进行对比。结果表明，HDC 模型在这些图任务上的表现优于 GNN，因为其利用超向量存储结构信息，有助于进行精确的节点分类。

Table 6: Comparisons between GNNs and HDC models.

<table><tr><td colspan="5">Dataset Configurations</td><td colspan="3">Model&#x27;s Accuracy (FP32)</td></tr><tr><td>Datasets</td><td># Nodes</td><td># Features</td><td># Edges</td><td># Classes</td><td>GCN</td><td>GIN</td><td>HDC Model</td></tr><tr><td>Cora [54]</td><td>2,708</td><td>1,433</td><td>5,429</td><td>7</td><td>81.5</td><td>77.6</td><td>82.6</td></tr><tr><td>CiteSeer [54]</td><td>3,327</td><td>3,703</td><td>4,732</td><td>6</td><td>71.1</td><td>66.1</td><td>72.0</td></tr><tr><td>NELL [2]</td><td>65,755</td><td>602</td><td>251,550</td><td>186</td><td>66.0</td><td>-</td><td>68.2</td></tr></table>

进一步地，我们评估了 FATE 在这些任务上的精度、存储开销与加速比，结果如图 17 所示。相对于 INT8 HDC 实现，FATE-G4 在不损失精度的前提下可实现最高 10× 的加速与 3× 的压缩率，表明 FATE 对实际应用具有很高的可扩展性。HDC 已在大规模生物应用中被深入研究，如基因组序列检索 [64] 和开放修饰搜索 [22]，进一步印证了 HDC 面向大规模任务的能力。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-07/fe5156f8-f30c-4618-8b68-4629b74589d2/33b02b1d86a3f0cf4315882eae9e06fcbe9cbc2e082b145eb5b2dc882bd81011.jpg)
图 17：图表示学习任务中，不同数据类型比例（左）、精度（中）与加速比（右）。

# 6 Related Works 相关工作

# 6.1 Compression of Neural Networks 神经网络压缩

为降低 DNN 的计算开销与推理时延，研究者提出了大量压缩方法，主要包括量化与剪枝。

量化方法包括权重量化聚类 [6, 7, 59]、二值化 [33, 63]、层内非均匀量化 [47, 55] 以及自适应量化 [40, 41] 等。剪枝方法则包括静态剪枝与动态剪枝：静态剪枝 [7, 26] 在训练完成后、推理前离线移除部分神经元；动态剪枝 [5, 32] 则在运行时决定哪些层、通道或神经元不再参与后续计算。

由于 HDC 的计算模型具有高维度与高并行等独特特性，现有 DNN 压缩方法难以直接迁移到 HDC；即使是最新的混合精度神经网络推理加速器 [50] 也无法高效支持 HDC 模型。因此，目前仍缺乏一种稳定可靠的压缩方法来充分释放 HDC 的性能潜力。

# 6.2 Binary HDC Design 二值 HDC 设计

二值 HDC 在效率上具有优势，但相较浮点或 INT8 HDC 存在精度损失。为提升精度，许多工作探索优化二值 HDC 框架 [8]。例如，SearcHD [19] 通过为每个类别存储多个二值超向量以容纳更多信息；BRIC [15] 使用随机投影方法提升编码质量；BinHD [13] 提出基于计数器的更新策略以实现更细粒度的类别超向量调整。然而，这些优化往往增加框架的计算复杂度。相比之下，FATE 在不增加框架复杂度的前提下，显著降低计算开销，并且可以与这些方法组合使用，以同时提升精度与性能。

# 6.3 HDC Accelerators HDC 加速器

除了在框架层面优化二值 HDC 外，已有大量工作在加速 HDC 方面作出尝试。部分方案基于新型存内计算技术以加速 HDC。例如，[16] 设计了三类（数字、阻变和模拟）关联记忆结构，用于在关联搜索中加速汉明距离计算；HD nanosystem [60] 则采用碳纳米管场效应晶体管与阻变 RAM 的三维一体化结构加速用于文本分类的二值 HDC。然而，这些方法仅支持二值超向量之间的汉明距离相似度。

另一类方案基于 FPGA 或低功耗架构。[20] 中的 LookHD 通过复用编码阶段的计算并压缩多个类别超向量，以降低推理时延与存储成本。F5-HD [52] 提出了一个模板化框架，可自动生成可综合的 FPGA HDC 架构，并提出了更硬件友好的编码方法以提高资源利用；该框架还通过支持多种数据类型，为精度/成本定制提供灵活性。

总体而言，这些已有加速框架在单次推理中仅支持一种数值数据格式，在资源利用与效率方面仍有优化空间。我们的方案正是通过引入“单次推理中可混合多种数值格式”的机制来进一步挖掘优化潜力，从而获得更高性能与灵活性。

# 7 Conclusion 结论

本文旨在构建能够灵活适配不同边缘计算场景需求的超维计算框架。我们对超向量的维度重要性进行了系统分析，并在此基础上引入混合位宽压缩，提出了一个面向资源感知的 HDC 架构 FATE：一种高效且灵活的超维计算模型压缩方案。FATE 通过稳定可靠的维度重要性度量与对应的混合位宽压缩策略，在资源感知架构设计的加持下，进一步降低了能耗与时延并提升资源利用率。实验结果表明，FATE 在仅引入极小精度损失的前提下即可获得显著性能提升。

在未来工作中，我们计划为 FATE 引入自动化优化闭环，通过搜索压缩参数实现自适应压缩。该机制可借助二分搜索策略，在不需要用户手工调参的前提下，根据精度阈值动态调整压缩率，从而在精度与效率之间自动取得最佳平衡。
