# Anda：基于可变长度分组激活数据格式的高效 LLM 推理

Chao Fang†,‡, Man Shi‡, *, Robin Geens‡, Arne Symons‡, Zhongfeng Wang†,* , Marian Verhelst‡

†中国 南京大学 电子科学与工程学院

‡比利时 鲁汶大学 KU Leuven ESAT-MICAS

Email: [fantasysee@smail.nju.edu.cn](mailto:fantasysee@smail.nju.edu.cn), [zfwang@nju.edu.cn](mailto:zfwang@nju.edu.cn), {man.shi, robin.geens, arne.symons, marian.verhelst}@kuleuven.be

摘要——当前广泛使用的 **权重量化（仅权重量化）大语言模型（LLMs）** ，通常采用低比特整数（INT）权重并保留浮点（FP）激活，在保持精度的同时显著降低存储开销。然而，这也使得 **能耗与时延瓶颈转移到了 FP 激活上** ——它们对应的内存访问和运算代价都很高。现有 LLM 加速器主要聚焦于计算优化，而往往忽略了 **对 FP 计算与数据搬移的联合优化** ，尤其是在推理中占主导地位的 FP-INT GeMM 运算上。

为解决上述问题，我们首先系统分析了不同 LLM 模块中激活精度敏感度及其对整体模型精度的影响。在此基础上，提出三方面创新：第一，我们提出  **Anda 数据类型** ：一种具有**组内共享指数位、动态尾数位分配**的自适应数据格式。第二，我们设计了一种迭代式 **训练后自适应精度搜索算法** ，可在不同 LLM 模块间优化比特宽度配置，在模型精度、能效和推理速度之间取得平衡。第三，我们提出一整套面向 Anda 的硬件优化技术，以充分挖掘该数据格式的优势，包括：基于比特平面的数据组织方案、采用比特串行计算的 Anda 增强型处理单元，以及运行时比特平面压缩器，从而在**存储、计算与内存访问**三方面协同优化。评估结果表明，在主流 LLM（包括 OPT、LLaMA 与 LLaMA-2 系列）上，针对 FP-INT GeMM 运算，Anda 相较于类 GPU 的 FP-FP 基线平均实现了  **2.4× 速度提升、4.0× 面积效率提升以及 3.1× 能效提升** 。此外，Anda 对不同应用场景、精度需求和系统性能要求具有良好的适应性，使得 LLM 推理能在更广泛的部署环境中高效运行。

# I. 引言

大语言模型（LLMs）[11], [63], [70], [72], [86] 在文本生成、问答系统、自动摘要等各类自然语言处理任务中展现出了卓越的能力。LLM 的成功在很大程度上得益于 **缩放定律（scaling law）** [3]——即随着模型规模、训练数据量及计算资源持续增加，模型性能会显著提升。GPT 系列 [5], [38], [63] 的演进很好地印证了这一规律：GPT-1 仅包含约 1.17 亿参数，而其后继版本 GPT-4 被普遍认为参数量已超过万亿级。然而，LLM 模型规模呈指数级增长，也带来了严重的部署挑战：对存储资源和计算资源的需求急剧攀升。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/b9101ec607c55801daccd4251fec9f9ece75b831e15238dfef59a3d9872baad1.jpg)

图 1. 使用可变长度分组 Anda 数据类型替换 FP 激活的整体流程示意。通过一次离线校准过程实现“即插即用”的激活替换，使在线推理阶段能够采用可变精度，从而在自适应精度组合搜索算法以及 Anda 感知架构的支持下显著提升速度与能效。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/fa146d690b1ff355d1baa2b4a868f82d39fbe1abf0294d49257a31014ec76e4c.jpg)

图 2. 在权重仅量化 LLM 中，针对不同模型规模和上下文长度的文本生成任务，FP-INT GeMM 运算所占比例。可以看到，在主流小于 4K token 的场景中，FP-INT GeMM 占比超过 90%，在超过 10K token 的长序列场景中仍占据较大比重。

为缓解上述压力，量化技术 [12], [16], [24], [51], [52], [66], [78] 被广泛应用于 LLM，以减小模型在存储和计算方面的消耗，并降低部署成本。为了 **最大程度压缩模型尺寸** ，当前 LLM 最常见的策略是**仅权重量化（weight-only quantization）** [8], [17], [24], [34], [35], [47], [51], [64], [66], [78], [81]，即对权重使用非常激进的低比特量化，而对激活仍保持较高精度，以应对激活中存在的离群值（outliers）[16], [77]。其中，应用最广泛的方案之一是 **W4A16** [24], [66]：将权重量化为 4 比特整数（INT4），而激活保留为 16 比特浮点（FP16）。这一方案能显著降低模型参数的存储和带宽需求，使得 GPU 显存占用减少近 **4×** [83]，从而有利于模型在资源受限的设备上部署 [51], [62]。

随着仅权重量化被大规模采用， **FP-INT GeMM 运算** [32] 已成为 LLM 推理中不可或缺的一环。如图 2 所示，在各种采用仅权重量化的 LLM 和不同上下文长度的文本生成任务中，FP-INT GeMM 占据了计算量的大头。在典型的**小于 4K token 的应用**里，FP-INT GeMM 平均占比超过 90%，而在 LongBench [4] 中超过 10K token 的长上下文应用里，该比例仍然相当可观。这种高度占比，凸显了 **针对 FP-INT GeMM 进行优化以提升 LLM 推理效率的紧迫性** 。

NVIDIA 新推出的 FP-INT GeMM 内核 [62] 以及一些专用 GPU 内核 [24], [35], [57], [78]，正是基于这一趋势而设计。然而，这些优化的 GPU 内核在实现上依然依赖现有 FP 单元：需要先将 INT 权重转换为 FP 值，再在 FP GeMM 运算单元上执行 [52]。为避免这一瓶颈，一些工作尝试设计专用的 FP-INT 算术单元 [32]，但指数对齐与归一化带来的额外成本依旧存在，硬件设计复杂度很高。另一种降低硬件成本的思路是**将 FP 激活转为块浮点（Block Floating Point, BFP）格式**进行计算 [13], [19], [44]。在 BFP 中，每个分组共享同一指数，从而消除了组内的指数对齐和归一化开销，使得运算可简化为整数算术。然而，对已训练好的网络直接将 FP 激活转换为 BFP 通常会带来较大的精度损失，为此往往需要代价高昂的再训练 [12]–[14], [26], [39], [44], [61], [85]，严重影响 LLM 的敏捷部署。另一种办法是采用较长的尾数字段 [32], [42] 来缓解精度下降，但随之而来的额外比特会显著增加计算与内存访问的能量消耗。

综上，在仅权重量化 LLM 推理中， **如何高效处理 FP 激活仍是主要瓶颈** ，而现有方法在模型精度、计算效率与能耗之间难以取得良好平衡。为突破这一困境，我们提出了  **Anda** ，以解锁高效的 LLM 推理。Anda 引入了一种新型的 **可变长度分组激活数据格式** ，并配合算法与硬件两方面的创新优化。如图 1 所示，Anda 首先在编译阶段利用与后训练仅权重量化 [25] 相同的校准数据，进行一次快速、训练无关的自适应精度搜索；在用户设定的精度约束之下，该流程会找到不同 LLM 模块所需的尾数比特长度，并将相应精度配置用于推理阶段的激活表示。将灵活的 Anda 数据格式与专用硬件架构相结合，可以在**较低精度**下执行占主导的 FP-INT GeMM 运算，从而显著提升仅权重量化 LLM 的推理速度与能效。更具体地，我们的贡献如下：

* 我们系统研究了在不同主流 LLM 模型和不同网络模块中使用 BFP 激活量化的可行性，并基于这些洞察提出  **Anda** ：一种具有共享指数和可调尾数宽度的 **可变长度分组激活数据格式** 。
* 我们提出了一种 **自适应搜索算法** ，在无需再训练的前提下，为不同 LLM 模块分配合适的尾数宽度。该算法在用户给定的精度损失容忍度下，实现模型精度、能效以及推理速度的综合平衡。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/43c57ce2bc7d57073f1b9b1434901efb1c5c07dc5289690d8dd4cabdd407dcf7.jpg)

图 3. 仅权重量化 LLM 模型的整体架构示意图。

* 我们设计了一套高效的  **Anda 感知硬件架构** ，包括：(a) 基于比特平面的激活数据内存布局方案；(b) Anda 增强型比特串行处理单元；(c) 运行时比特平面压缩器。针对主流 LLM 的全面评估表明，相较于现有最先进（SotA）硬件方案，Anda 系统在处理速度上平均提升  **2.4×** ，面积效率提升  **4.0×** ，能量效率提升  **3.1×** 。

全文结构如下：第二节回顾仅权重量化 LLM 与 BFP 格式的优势与瓶颈，并定量分析在共享指数与减少尾数比特下 LLM 推理精度的敏感度。基于这些结论，第三节给出所提出的 Anda 数据格式，并介绍在给定精度约束下快速优化尾数长度的算法。第四节进一步提出 Anda 优化的硬件架构，并在第五节给出系统层面的综合性能提升和与 SotA 方案的对比。第七节对全文进行总结。

# II. 背景与动机

## A. 仅权重量化 LLM

仅权重量化 [8], [17], [24], [34], [35], [47], [51], [64], [66], [78], [81] 已成为提升 LLM 推理效率的关键技术之一。与同时量化权重和激活的**权重–激活联合量化** [12], [16], [52], [79], [89] 不同，仅权重量化只对模型参数进行压缩，并且量化策略更加激进。

图 3 展示了一个仅权重量化 LLM 的整体架构：模型由多层 Transformer Block 组成，每个 Block 内包含注意力层和前馈层。图中浅蓝色背景区域标出了涉及 FP-INT GeMM 运算的主要计算模块，可根据 FP 激活所在位置划分为四类模块：

1）第一类是  $A_{qkv}$ 分别与  $W_q$、$W_k$、$W_v$ 相乘，生成查询矩阵  $Q$、键矩阵  $K$、值矩阵  $V$；

2）第二类是  $A_o$ 与  $W_o$ 相乘得到注意力输出矩阵；

3）另外两类则是前馈层中的上投影和下投影模块，分别涉及  $A_u$ 和  $A_d$ 与其对应权重的乘法。

在存储方面，仅权重量化 LLM 具有显著优势 [62], [66]。与 W8A8 权重–激活联合量化 LLM [79] 相比，W4A16 仅权重量化 LLM [51] 在保持相近模型精度的同时，可将参数存储需求进一步压缩近一半 [83]，因此非常适合在算力和容量有限的边缘设备上部署。然而，在当前 GPU 计算范式下，执行一次 W4A16 的 FP-INT 运算所消耗的能量 **约为 W8A8 纯 INT 运算的 1.7×** [42]。其原因在于：访问 FP 激活的能耗普遍高于访问 INT 权重 [31]，且 FP-INT 运算单元本身需要较复杂的硬件结构 [32]。因此，**优化 FP 激活表示是提升仅权重量化 LLM 整体效率的关键突破口。**

## B. 块浮点（Block Floating Point）

为了优化 LLM 的效率，降低 FP16 激活在计算与存储上的开销至关重要。 **块浮点（BFP）** [19] 通过在一个分组内共享指数，在保留动态范围的同时弱化离群值影响，并简化运算流程，是一种颇具潜力的方案。BFP 格式通常由两个核心参数决定： **组大小（group size, GS）**与**尾数长度（mantissa length, M）** 。

图 4 展示了将 FP16 张量转换为不同 BFP 格式的过程。首先，将 FP16 张量按照一定组大小划分为若干组；在每一组内，选取指数最大的元素作为共享指数，然后根据指数差异对其他元素的尾数执行右移对齐；超出指定尾数长度的比特会被截断，而全零的尾数则代表数值 0。如图 4 所示，这一转换可能导致精度损失：一部分元素尾数被截断，甚至被量化为 0，从而对模型精度构成潜在威胁。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/7fd16ad496b57e203e1ff1a77e1800a8f1c1fb64013afa4c42d4a42b122afe42.jpg)

图 4. 将一组 FP16 数字转换为不同 BFP 格式的过程。BFP 由两个关键参数决定：组大小（GS）和尾数长度（M）。

现有针对 BFP 精度损失的研究大致可以分为两类：

* 一类是  **BFP 感知训练** ，即在量化之后对模型进行微调 [12]–[14], [23], [26], [39], [41], [44], [61], [85]。这类方法虽然能够有效恢复精度，但训练开销巨大，不适合追求快速部署的 LLM 场景。
* 另一类是 **直接把预训练 FP 模型转换为 BFP 表示** [22], [23], [44], [50], [61]。为了避免严重精度下降，这类方法往往需要较长的尾数，从而增加计算与存储成本，削弱了采用 BFP 的优势。为减轻存储开销，一些方案如 FIGNA [32] 与 [42] 提出在计算时动态将 FP 激活转换为 BFP：在内存中仍以 FP16 存储激活，在计算前扩展为共享指数、长尾数的 BFP 表示。虽然这种做法能在计算阶段利用 BFP 的优势，但也意味着 **激活内存占用并未减少** 。

为了同时避免昂贵的再训练和大量激活存储开销，我们希望找到一种方案，能够 **在不再训练的前提下快速地将 FP 激活转换为 BFP 激活** ，并在 LLM 推理过程中充分利用 BFP 在计算与存储上的优势。为此，有必要在 LLM 的特性下，进一步挖掘**使用较短尾数的 BFP 格式**的潜力。

## C. 激活优化的机会

我们通过分析 **将激活转换为 BFP 格式时尾数长度减少对模型精度的影响** ，来寻找 LLM 激活优化的空间。具体地，我们将 FP-INT GeMM 中的激活张量  $(A_{qkv}, A_o, A_u, A_d)$ 从 FP16 转为 BFP，如图 4 所示，并使用 WikiText2 数据集上的困惑度（perplexity, PPL）作为评估指标，PPL 越低表示精度越高。我们在实践中假定 **1% 的精度损失容忍度** ，以此为约束寻找在可接受损失范围内的高效激活表示方式。

 **对组大小的敏感度：**图 5 展示了两种不同 LLM 在各类尾数长度下，对共享指数组大小的敏感度。可以观察到一个明确的权衡：组越大，所需的尾数长度通常就越长，才能保持相近精度；而较小的组虽然有利于精度，但会削弱利用组内并行和共享的计算优势。综合考虑后，我们在后续实验中选取**组大小为 64** ，在计算效率与精度容忍度之间取得折衷。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/f5df511a75a2935e323a8f93324931738199aec78df77a9ae568ff80b2064e13.jpg)

图 5. LLM 对 BFP 组大小（GS）和保留尾数比特数的精度敏感度。

**对 LLM 模型本身的敏感度：**在固定组大小为 64 的前提下，我们进一步在更多近年的 LLM 上展开研究。图 6 显示，不同模型对尾数减少的敏感度是不同的。以 OPT 系列为例，OPT-2.7B、OPT-6.7B、OPT-13B 和 OPT-30B 对尾数精度相对不敏感，可以直接去掉 5 个尾数比特，而其他一些模型只能容忍去掉 4 位尾数。随着被移除的尾数比特增多，不同模型之间在精度敏感度上的差异也愈发明显。这一观察启发我们：**可以采用“可变长度” BFP 数据类型，对不敏感模型更激进地压缩，而对敏感模型则保守一些。**这也进一步引出了一个问题：在同一个 LLM 内部，不同模块的激活对精度是否有不同的敏感度？

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/12bc671f7da59980ef773e35f0e8c0c760417090fcf03906dee4089f23b2123f.jpg)

图 6. 不同 LLM 在不同保留尾数比特数下的相对精度变化。

**对 LLM 内部模块的敏感度：**我们最后考察在同一 LLM 内，不同模块激活的尾数长度对整体精度的影响。具体地，对 OPT-6.7B、LLaMA-7B 和 LLaMA2-7B，我们分别只调整  $A_{qkv}$、$A_o$、$A_u$ 和  $A_d$ 的尾数长度，而将其他三个模块的尾数固定在 13 位。图 7 总结了结果，可以看到：在所有三种模型中， **不同模块的激活精度对整体性能的影响并不相同** 。其中，$A_{qkv}$ 一贯表现为最敏感的模块，而  $A_d$ 在 OPT-6.7B 中相对不敏感，但在 LLaMA 系列中影响更为显著。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/58b1bee6f5331baa0dabc6183fe0a02f75a2bbf5b92cec68ac3663df3966c06c.jpg)

图 7. 在仅对  $A_{qkv}$、$A_o$、$A_u$ 或  $A_d$ 中某一个模块剪裁尾数比特时，OPT-6.7B、LLaMA-7B 与 LLaMA2-7B 的相对精度变化。

综合上述研究，我们得到关于在 LLM 中应用 BFP 的几个重要结论：

(a) 在一定范围内减少尾数比特时，LLM 仍能保持良好性能；

(b) 不同 LLM 模型对尾数减少的敏感度不同；

(c) 在单个 LLM 内，不同模块对精度降低的敏感度也各不相同。

这些观察共同激励我们提出一种 **新的可变长度分组 FP 激活数据格式** ，并配套一套 **训练后量化（PTQ）方法** ，可在任意 LLM 上快速选择可接受的尾数减少方案。

# III. ANDA 数据格式

本节介绍 Anda 数据格式的核心特点，并说明其在仅权重量化 LLM 推理中的 FP-INT 运算优势。随后，我们提出一种 Mantissa 位宽搜索方法，用于在给定精度约束下高效找到最优 Anda 精度组合。

表 I 给出了 Anda 与已有 BFP 格式在计算和存储上的对比。

TABLE I ANDA FORMAT DEFINITION IN CONTRAST WITH PRIOR BFP FORMATS

## A. Anda 格式特性

基于前文的分析，我们提出  **Anda 格式** ：一种为高效 LLM 推理而设计的 **可变尾数长度 BFP 方案** 。Anda 的结构由 1 位符号位、共享指数以及可变长度尾数组成，转换流程继承了图 4 中传统 BFP 的基本过程。其关键特性在于： **能够根据不同张量对精度的敏感度，动态选择其尾数长度** ，并在同一张量内部保持统一尾数宽度，从而在精度与效率之间实现精细权衡。

表 I 将 Anda 与现有 BFP 格式进行了对比，并根据所支持的尾数长度类型进行分类：

* Uni-length 格式（如 VS-Quant [12] 与 FIGNA [32]）使用固定尾数长度；
* Multi-length 格式（如 FAST [85] 与 DaCapo [41]）允许从少数几个预制长度中选择（例如 2/4/8 bit 等）；
* 相比之下，Anda 提供了 **连续范围的尾数可选长度（1–16 bit）** ，使得我们能够在不同 LLM 模块间进行更细粒度的精度控制。

在第四节将要介绍的专用硬件支持下， **更小的尾数宽度可以直接转化为更低的推理时延、更少的计算成本与更小的存储成本** 。因此，Anda 格式可以在模型中不敏感的部分采取更激进的压缩，而在关键部分保留更高精度，从而在整体上实现更好的精度–效率平衡。

## B. 使用 Anda 格式的高效 FP-INT GeMM

为了直观展示用 Anda 替代 FP16 激活的优势，我们对比若干 SotA 方案在 GeMM 工作负载下的处理流程。以 W4A16 量化为例，我们考察以下几种 FP-INT GeMM 实现路径：

(a) 现有 GPU 平台上的方案 [52]；

(b) 带有专用 FP-INT 单元的增强型 GPU 方案；

(c) FIGNA 提出的动态 BFP 转换方案 [32]；

(d) 我们提出的 Anda 方案。

图 8 给出了这四种方案的对比，其中颜色标识了不同阶段使用的数据类型。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/bd48bc55d17a21d4859a10a0240e92c7e0a07ba3e814af273b2532f9e12d48a8.jpg)

(a) 当前基于 GPU 的方案

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/ef625c6d070389dec9b59738af910eb2ef5644e1d8eb82031c7011d67e1fa576.jpg)

(c) FIGNA 方案

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/e47f5f8485366a123798f638daedce3c729541d7f801d5101958d4a0529077bf.jpg)

(b) 带 FP-INT 单元的增强型 GPU 方案

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/7525c5f65feabaf975847717cd0d54a20b8621ab5895b01762066e9bf09b1b67.jpg)

(d) Anda 方案

图 8. (a) 现有 GPU 上的计算方案；(b) 增强型 GPU（配有专用 FP-INT 单元）的方案；(c) FIGNA 方案；(d) 我们提出的 Anda 方案在 FP-INT GeMM 中的单次计算流程。Anda 方案显著减少了存储空间、访问成本及计算开销，并支持能效友好的精度可伸缩运算。

**(a) 现有 GPU 方案：**如图 8(a) 所示，在主流 GPU 上，缺乏专用 FP-INT 运算单元，INT4 权重需要先转换为 FP16，再在 Tensor Core 的 FP16 模式下执行 GeMM。这不仅带来了额外的格式转换开销，还迫使我们使用成本更高的 FP 运算。

**(b) 带 FP-INT 单元的增强 GPU：**如图 8(b) 所示，如果在 GPU 上集成专用的 FP-INT 运算单元，可以避免将 INT4 权重转换为 FP16，从而减少数据转换和部分计算开销。但正如 FIGNA [32] 所指出的，FP-INT 单元所需的指数对齐和归一化仍然带来较高的计算开销。

**(c) FIGNA 的动态 BFP 方案：**为高效部署 W4A16 LLM，FIGNA 提出在配套硬件支持下，使用一个 BFP 变体来替代 FP-INT 单元。如图 8(c) 所示，激活在内存中按 FP16 存储，在计算前转换为 FIGNA 格式；随后用 14 位尾数与 INT4 权重做 GeMM 运算，再将结果转换回 FP16 写回内存。该方案通过将昂贵的 FP GeMM 转换为 INT 运算，减少了计算开销。但由于激活在内存中仍以 FP16 存储，在计算过程中需要频繁从 FP16 转换到 FIGNA，这部分开销会抵消不少收益。

 **(d) 我们提出的 Anda 方案：**如图 8(d) 所示，Anda 的计算流程在上述方案基础上具有以下独特优势：

1）激活不再以 FP16 格式存储于内存，而是**直接以 Anda 格式存储** ，从根本上减少存储与访存开销，同时避免重复的数据格式转换；

2）组内共享指数使得我们可以在组内使用纯 INT 点积运算，再在组间使用 FP32 累加，从而大幅降低 FP-INT GeMM 的计算复杂度；

3）可变长度尾数使得点积运算与内存访问都可以根据实际需要使用 **最小必要字长** ，进一步降低能耗与时延；

4）在写回内存之前，仅需将最终 FP32 结果一次性转换为 Anda 格式，从而将格式转换开销降到最低。

## C. 自适应精度组合搜索

为了在后训练阶段快速完成 Anda 精度配置，并发挥硬件优势，我们提出了一种 **自适应精度组合搜索算法** ，用于在仅权重量化 LLM 中离线优化激活精度。该算法的基本思想包括两点：

(a) 根据前文图 7 中的敏感度分析，我们将搜索空间收缩为 **仅对四类关键张量的精度进行组合** ：$A_{qkv}$、$A_o$、$A_u$ 和 $A_d$。精度组合可以表示为一个四元组

[

[M_{qkv}, M_o, M_u, M_d].

]

(b) 我们使用与权重仅量化后训练 [24], [51], [66] 相同的一小部分校准数据（数千 token、数百个 batch）进行一次性搜索，而非层级细粒度调整。虽然以前的一些逐层方法 [18], [28], [76] 能实现更精细的精度分配，但其耗时较长，会严重拉长部署周期；相比之下，我们采用“按模块”的精度统一策略，在维持层间一致性的同时，可以快速找到 **全局模块级精度组合** ，易于集成到现有后训练部署流程中。

算法 1 给出了自适应精度组合搜索的伪代码。其输入为 LLM 模型  $L$、校准数据集  $D$、可接受的精度损失阈值  $\delta$ 以及最大迭代次数  $N$。其中，$\delta$ 可以视作性能退化的上界，而 $N$ 用作终止条件，保证搜索在合理时间内结束。算法的目标是在有限迭代内找到最优的四元组精度组合，在给定精度约束下实现最低的计算开销。整体流程分为三个步骤：

**步骤 1：初始化搜索起点。**首先构造一个优先队列，其中放入各模块采用同一精度的若干组合，从激进（例如 [4,4,4,4]）到保守（例如 [13,13,13,13]）一一列出。这样既可以快速找到较好的解，又可以确保搜索空间中一定存在可行解，这一点已在图 6 的实验中得到验证。

**步骤 2：选取当前最有前景的组合。**在每次迭代中，从优先队列中取出**BOPs（bit operations）最小**的精度组合，并将其加入到“已访问集合”中。BOPs 指标 [1], [43], [49], [71] 用于快速估算当前组合对应的理论计算量：即在给定精度下所有乘法运算所需的比特操作总数。这个指标可以帮助我们在不做完整模型推理的前提下预估计算成本，优先尝试更有潜力的组合。随后，在校准数据集上评估该组合的精度。

**步骤 3：更新并松弛最优组合。**若当前组合在满足精度约束的前提下，BOPs 低于已有最优解，则将其更新为新的最优组合。随后，我们对该最优组合执行“松弛”操作：分别将四个模块中的某一个尾数长度减 1，得到若干邻近候选。例如，若当前最优为 [6,7,5,5]，则邻居为 [5,7,5,5]、[6,6,5,5]、[6,7,4,5]、[6,7,5,4]。对尚未访问的邻居组合，将其加入优先队列。若当前组合未满足精度约束，则不做更新。步骤 2 和 3 持续迭代，直到达到最大迭代次数或搜索空间被穷尽。

算法 1：自适应精度组合搜索

```text
Algorithm 1: Adaptive Precision Combination Search
Input: LLM model L, calibration dataset D, accuracy loss tolerance δ, max iterations N
Output: Optimized precision combination best_comb denoted as a 4-tuple [M_{qkv}, M_o, M_u, M_d]

// S1: Initialize search starting points
1:  Q ← PriorityQueue([4, 4, 4, 4], ..., [13, 13, 13, 13]);
2:  best_comb ← null, best_bops ← ∞;
3:  iterations ← 0, visited ← {};
4:  fp_acc ← EvaluateAccuracy(L, D);

5:  while iterations < N do
    // S2: Check the promising combination
6:      bops_eval ← Q.map(EvalBOPs);
7:      curr_bops ← min(bops_eval);
8:      curr_comb ← Q.get(bops_eval.index(curr_bops));
9:      visited ← visited ∪ {curr_comb};
10:     anda_acc ← EvaluateAccuracy(L, D, curr_comb);

    // S3: Update and relax the best combination
11:     if curr_bops < best_bops and anda_acc ≥ (1 − δ) · fp_acc then
12:         best_comb ← curr_comb;
13:         best_bops ← curr_bops;
14:         neighbors ← GenerateCandidates(curr_comb);
15:         foreach n ∈ neighbors do
16:             if n ∉ visited then
17:                 Q.push(n);
18:             end
19:         end
20:     end

21:     if Q.empty() then
22:         break;
23:     end
24:     iterations ← iterations + 1;
25: end

26: return best_comb
```

## D. 精度组合搜索效率

我们的目标是，在后训练阶段对仅权重量化 LLM 的 FP 激活进行高效的精度优化。大部分权重仅量化流程 [24], [51], [66] 都会使用一小部分校准集，这恰好可以复用到激活精度搜索中。为了避免显著增加部署时间，搜索过程必须足够快速。因此，我们将算法设计成：在给定的精度容忍范围内， **用少量迭代找到接近最优的精度组合** ，而非追求严格的全局最优。

算法的高效性主要来自两点：

1）我们只在当前组合带来更低计算成本的前提下更新“最优组合”，并在此基础上使用类似梯度下降的“松弛”方式加速收敛。这种策略虽然有可能错过全局最优，但能在有限迭代内找到性能优良的解；

2）我们为算法设置了迭代次数上限，以确保搜索在有限时间内完成，避免影响部署周期。考虑到本问题仅涉及 4 个精度变量，搜索空间相对有限，因此算法通常能在少量迭代内收敛。每次迭代的主要开销是：在校准集上进行一次前向推理以验证当前精度组合。

为了进一步验证搜索效率，我们将该算法与传统穷举式搜索 [12]–[14] 在 OPT-125M 模型上进行了对比。如图 9 所示，在 OPT-125M 的精度组合搜索空间中，可能的组合数量超过 1 万，而我们的算法仅用 10 轮迭代就找到了满足 1% 精度损失约束的全局最优组合 [7,7,6,5]。在实际实现中，我们通常将迭代上限设为 32 次，从而在保证搜索时间可控的条件下获得接近最优的精度组合。由于算法只需前向推理，不涉及回传或复杂优化求解，其整体运行时间约为 Omniquant [66] 的一半、GPTQ [24] 的十分之一，是当前后训练仅权重量化 LLM 中相当高效的方案之一。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/a1a1d0b928ed51643b74399099007b134f98052b387c0c8ebbd169c42b68553e.jpg)

图 9. 在 OPT-125M 模型上，给定 1% 精度损失约束时，自适应精度组合搜索算法的搜索过程。算法在约 10 次迭代内找到全局最优解。

# IV. ANDA 架构

本节首先介绍 Anda 架构的三大核心组件：

(a) 适用于可变长度激活数据的 **比特平面存储布局** ；

(b)  **Anda 增强型比特串行处理单元（APU）** ；

(c) 输出激活的 **运行时比特平面压缩器（BPC）** 。

这三部分协同工作，共同提升存储效率、计算性能和能量利用率。最后，我们给出整体 Anda 系统架构，并说明各组件如何协同实现高效的 LLM 推理。

## A. 比特平面数据布局方案

由于 Anda 激活的尾数长度是可变的，因此需要仔细设计其在片上存储中的布局，以维持规则、可预测的访存模式；否则，一旦数据布局不合理导致访存不规则，就会抵消 Anda 带来的效率提升。

为解决这一问题，我们提出了如图 10 所示的 **比特平面数据布局方案** 。与以往固定长度布局方法 [30], [41], [61], [67] 将每个 FP 元素视作不可拆分的“原子单元”不同，我们从比特平面的角度重新组织组内 FP 数的符号位、指数和尾数。通过引入 **转置式（transposed）布局** [48]，我们将多个数中同一比特位的重要性（如第 0 位、第 1 位等）沿着比特平面打包，从而保证访存时的规整性。

考虑典型片上存储的字宽，我们将  **64 个 Anda 值划为一组** ，以实现比特平面布局。如图 10 所示，Group #0 展示了 4 位尾数的 Anda 数在内存中的布局，而 Group #1 展示了 5 位尾数时的布局。尾数长度的变化只体现在内存地址深度不同，而对**存储带宽利用**影响很小，可以通过地址生成逻辑轻松管理。因此，在上述两种情况下，比特平面布局都能高效地支持不同尾数长度，同时保持访问模式的一致性。此外，这种组织方式天然适合并行处理，也为我们在下一小节中设计针对 Anda 的**比特串行处理单元**提供了基础。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/a55eae436667a48c87db58a349b0cde4bed07d7508d8954b85a1cdeb5aadb1de.jpg)

图 10. 用于可变长度激活数据高效存储的比特平面布局方案。

## B. Anda 增强型比特串行处理单元

如图 11 所示，**Anda 增强型比特串行处理单元（APU）**是 Anda 架构中的核心计算单元，由一个 Anda 处理单元（PE）和一个 FP 累加器构成。Anda PE 负责对可变长度 Anda 激活与 INT 权重进行点积运算，并与比特平面存储布局深度结合，从而提升性能；FP 累加器则负责完成跨组累加，构成一个完整的 APU。

计算流程大致如下：PE 首先将激活的符号位和指数寄存到内部寄存器中；同时，INT 权重通过双缓冲结构载入 PE，使得权重加载与计算可以重叠进行，从而减少加载延迟。随后，PE 依次读取激活尾数的比特平面，与对应的 INT 权重进行乘加运算。由于采用比特串行方式，PE 可以 **在不增加额外硬件开销的情况下适配不同尾数长度的 Anda 数据** 。

为了进一步提升硬件效率，我们在 Anda PE 中采用了**“先按元素再按比特平面”的累加模式**：在每个比特平面内，先通过加法树对该平面内的 64 个元素加和，得到该比特平面的部分和；之后，使用一个共享累加器按比特顺序完成所有比特平面的累加。相比于直接对每个元素维护中间结果，这种设计具有如下优势：

* 只需为每个比特平面存储一个部分和，显著降低暂存寄存器的需求；
* 所有后续的移位与累加操作只作用在单一部分和上，而非每个元素，从而减少数据移动与处理开销；
* 使用一个共享的累加器完成比特平面累加，大幅降低硬件资源消耗。

在完成所有比特平面的累加后，Anda PE 会根据当前尾数长度对点积结果进行动态移位，并利用共享指数将结果转换为 FP16 表示。随后，该结果与 INT 权重的组间缩放因子相乘，并通过 FP 累加器在不同组之间进行 FP32 累加。最终，FP32 累加结果再转换为 FP16 输出。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/689fcc4058ae1aa4eb8a8f4df222f15556b6ce73e64af5835195db0d1d6878e8.jpg)

图 11. Anda 增强型比特串行处理单元架构。它支持 Anda 激活与 INT 权重间的高效点积运算。

## C. 在线比特平面压缩器

**比特平面压缩器（BPC）**是 Anda 架构中的另一关键模块，用于在运行时将 FP16 激活高效转换为压缩后的 Anda 格式。BPC 能同时并行处理大量激活值，并以比特串行的形式输出，从而支持可变长度 Anda 激活的存储与传输。

图 12 展示了 BPC 的架构。它包含 16 条并行“通道（lane）”，每条通道可以同时处理 64 个 FP16 激活。每个通道首先使用 FP 字段提取器将 FP16 输入拆分为符号、指数和尾数。随后，**最大指数捕获器**会找出组内最大的指数，并计算每个元素指数与之的差值。

压缩流程的核心是**“并行转串行”的尾数对齐器（parallel-to-serial mantissa aligner）**。如图 12 所示，在对齐过程中，每一周期都会将每个元素的“指数差”减一，直至为零。当某个元素的指数差为零时，该元素的最高有效位尾数会在当周期被“移出”；否则，该元素在该周期的输出比特为 0。所有元素在当前周期“移出”的尾数位，会被打包为一个比特平面的输出。这个过程持续多周期，直到输出比特平面的数量等于预设尾数长度为止。通过这种方式，我们可以**直接生成按比特平面对齐的压缩尾数**。随后，所有通道输出的比特流连同符号位和共享最大指数一起传给数据打包单元，以符合前文设计的比特平面存储方案。

与已有比特并行对齐器 [32], [85] 相比，我们的比特串行对齐器只需要一个比较器和一个移位器即可实现，而后者往往需要多个并行移位器和比较器来支持单周期动态移位 [15]。虽然比特串行方式会带来若干周期延迟，但这部分延迟能够与 APU 的计算过程在时间上高度重叠，对整体系统性能的影响相对较小。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/5e7f28327edf3dc46bf246270ac040b5bdc735d170f01298bb5ab95a0a74c78c.jpg)

图 12. 在线比特平面压缩器的架构，以及在并行转串行尾数对齐器中完成的尾数对齐流程。

## D. 整体架构

图 13 展示了完整的 Anda 系统架构，包括顶层控制器、地址生成器、激活缓冲区、权重缓冲区、矩阵计算单元（MXU）、向量单元以及比特平面压缩器等模块。整体 LLM 推理流程如下：

1. **指令配置** ：通过顶层控制器的 I/O 接口，将指令写入指令存储器。顶层控制器在运行时负责驱动地址生成器。
2. **地址生成与数据访问** ：地址生成器为激活缓冲区与权重缓冲区生成读写地址。两者都采用前文提出的比特平面数据布局，以提高访存效率。
3. **矩阵计算（GeMM）** ：MXU 中包含一个  $16\times 16$ 的 APU 阵列，采用典型的 **输出驻留（output stationary）数据流** [45] 执行 FP-INT GeMM 运算。权重数据分发器通过寄存器支持权重加载与计算的重叠，并以行为单位向各 APU 广播权重；激活数据分发器则每周期提供一行比特平面向量，将其沿列方向广播，最大化输入复用。
4. **输出压缩与非线性运算** ：完成 GeMM 后的输出结果通过输出数据分发器送入 BPC。与 MXU 相辅相成的向量单元负责执行 Transformer Block 中的各种非线性函数。
5. **激活压缩** ：来自 MXU 或向量单元的 FP16 输出，可以选择是否由 BPC 压缩为 Anda 格式，以减少存储负担。
6. **缓存回写** ：处理后的激活会写回到激活缓冲区。
7. **外部存储交互** ：最终激活结果会被传送至外部内存，用于后续推理阶段。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/f31eb73accbff4d621100e6c27cee86c5d16c50acbf2f4c12926c4e446111b16.jpg)

图 13. Anda 系统架构。

# V. 评估

## A. 实验设置

**LLM 基准：**为了验证方法的泛化能力，我们在 PyTorch 与 Hugging Face 框架下，对多个开源 LLM 进行评测。模型在 WikiText-2 [60]、Penn Treebank (PTB) [59] 和 C4 [65] 数据集上进行验证。所选模型参数规模从 1.3B 到 30B，涵盖 OPT [86]、LLaMA [72] 与 LLaMA2 [73] 系列，便于在不同规模和架构上评估 Anda 的有效性。

**量化基线：**为了验证用 Anda 替换 FP 激活后的模型精度，我们采用如下对照组：

(a)  **全精度基线** ：激活与权重均为 FP16；

(b)  **权重仅量化 PTQ 基线** ：采用 Omniquant [66] 的 W4A16g128 方案，即权重量化为 4 bit，组大小为 128；

(c)  **无损 BFP 基线** ：采用 FIGNA [32] 的扩展尾数方案，通过较长尾数避免精度损失；

(d)  **激进 BFP 基线** ：采用 VS-Quant [12] 的 4 bit 激活尾数方案。为公平起见，由于我们工作处于 PTQ 场景，因此直接使用 VS-Quant 的 4 bit 数据格式，但不执行通常所需的再训练。

对于 (c)、(d) 和我们的 Anda 方法，都是在 (b) 的基础上进一步将激活转换为 BFP，且 BFP 的组大小统一设为 64。

**硬件基线：**我们还将 Anda 的硬件架构与以下几种方案进行对比：

(a)  **FP-FP** ：基于 FP16 Tensor Cores 的空间加速器 [84]，代表当前主流 GPU 架构 [69]；

(b)  **FP-INT** ：在 Tensor Core 上增强专用 FP-INT 运算单元的加速器；

(c) **iFPU** [42]：采用比特串行 INT 权重、并在计算时动态将 FP 激活转换为 BFP 的空间加速器；

(d) **FIGNA** [32]：在 (c) 的基础上，通过比特并行计算和优化 BFP 尾数长度进一步提高效率。

为公平对比，所有系统配置为相同的时钟频率（285 MHz）、等效峰值吞吐量和片上内存资源 [68]。

**评估方法：**我们的评估覆盖模型精度与硬件效率两部分，重点优化占主导的 FP-INT GeMM 运算，其他部分（如 KV cache [56]）仍使用 FP16 表示。

* 在精度方面，我们采用：

  (a)  **PPL 指标** [33]（序列长度为 2048）；

  (b) FIGNA、VS-Quant 与 Anda 相对 Omniquant 的 **精度损失** ；

  (c)  **BOPs 减少比例** ，用于衡量理论计算量的下降。这里我们将一次 FP16-INT4 运算约等价为 64 个 bit 操作，以刻画其比特级复杂度。
* 在硬件方面，我们从两层级进行分析：

  1）在单 PE 层面，比较不同方案的面积与功耗，并计算面积效率（TOPS/mm²）和能量效率（TOPS/W）；

  2）在系统层面，将 Anda 与上述基线架构对比，重点考察在 FP 激活由 Anda 替换时的加速比与能效提升。

与已有研究 [27], [32], [42], [79] 一致，我们在系统层面的评估中假设 LLM 的 batch size 为 1，并使用 WikiText2 数据集中可接受的最大输入序列长度。PE 级基线与 Anda 系统一并使用 SystemVerilog RTL 实现，在 16nm 工艺下通过 Cadence Genus [6] 综合，工作频率为 285 MHz，电压为 0.8V。功耗评估基于综合后网表的 VCD 文件，并由 Genus 分析得到。系统级能量与性能通过经功能仿真验证的周期精确模拟器进行评估。外部 DRAM 模型采用 HBM2，访问能量为 3.9 pJ/bit，带宽为 256 GB/s [36]。

## B. 推理精度

我们使用自适应精度搜索算法得到的 Anda 格式，在所有基准模型和数据集上进行验证。对于每个基准，我们从训练集随机采样 128 条长度为 2048 的序列作为校准数据 [66]，并将迭代上限设为 32。由于 Anda 能根据用户定义的精度要求自适应地调整尾数比特，我们分别在两种精度容忍度下报告结果： **0.1%（几乎无损）与 1%（大多数场景可接受）** 。

表 II 总结了各个基准上的 PPL、相对精度差以及 BOPs 降低情况（黑色为 PPL，红色为相对精度下降，绿色为 BOPs 降低比例）。需要说明的是，由于校准集与验证集并不完全一致，少数情况下验证集上的精度损失会略微超过设定阈值，这是正常现象。如表中所示，Anda 在维持接近目标精度的同时，实现了显著的 BOPs 减少。例如，在 WikiText2 数据集上，在 0.1% 精度损失约束下，Anda 的 BOPs 可下降 1.80–3.10×；在 1% 精度约束下，BOPs 可减少 2.44–3.31×。与 FIGNA 在较短尾数下约 1.23× 的 BOPs 降低相比，Anda 利用不同张量采样不同尾数长度，在相近精度损失下可进一步减少 1.46–2.69× 的 BOPs。与需要再训练的 VS-Quant 相比，直接部署其 4 bit 激活格式虽然计算量减少了 4×，但精度损失严重，例如在 OPT-1.3B + WikiText2 上，VS-Quant 的精度下降达 27.96%。而 Anda 在同一场景中，在只损失约 0.74% 精度的前提下，便能获得接近 3× 的 BOPs 减少。整体而言，Anda 在各种模型和数据集上都展现出稳定的精度–效率优势，并验证了自适应精度搜索算法的稳健性。

（下表保留数字与方法名不变，仅说明：表内为各模型在 WikiText2、PTB、C4 三个数据集上的 PPL，行间的 “Ours (0.1%)” 与 “Ours (1%)” 分别为在 0.1% 与 1% 精度约束下的 Anda 结果。）

*说明：为与 PTQ 场景公平对比，我们直接采用 VS-Quant 的 4 bit 格式，而不执行其通常依赖的昂贵再训练。*

图 14 展示了在 0.1% 与 1% 精度约束下，各 LLM 在不同数据集上的 **最佳精度组合** 。可以看到，对于同一模型，不同精度约束会显著影响最终的组合，这说明自适应精度搜索在根据模块敏感度分配尾数方面非常关键。按模块类型观察，$A_{qkv}$（对应 Q、K、V 投影层）通常倾向于更高精度；而前馈层的 $A_u$ 与 $A_d$——尤其是 $A_d$——更适合进一步量化，说明其对精度降低有更高容忍度。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/0efad0741f7c6ba26fc577b2e82ecde44ae160547d3852a2240203f20b12c001.jpg)

图 14. 在不同数据集、不同精度约束下，各 LLM 的最佳精度组合。

## C. PE 级评估

我们在 PE 级别将 Anda PE 与以下几类单元进行比较：

* GPU 式 FP-FP 单元 [58]；
* 增强型 FP-INT 单元；
* iFPU [42] 的专用 PE；
* FIGNA [32] 的专用 PE。

此外，我们引入 FIGNA-M11 与 FIGNA-M8 作为基线，分别对应保留 11 位与 8 位尾数、满足 0.1% 与 1% 精度约束的两种固定尾数配置。记  $\mathbf{M}(x)$ 为保留尾数比特数为 x 的情况。为确保公平性，所有 PE 在每周期的计算吞吐量保持一致，并在相同点积任务下评估面积效率与能量效率。

图 15(a)(b) 分别给出了 Anda 与其他 PE 的面积与功耗对比。Anda 相较于 FP-FP 与 FP-INT 单元，在面积和功耗上都降低到 60% 以下，这主要得益于共享指数消除了复杂的对齐与归一化逻辑。与 iFPU [42] 相比，Anda 避免了为维持 FP16 精度而使用的高成本超宽乘法器和寄存器，使面积减少约 12%，功耗减少约 29%。相较于 FIGNA，由于采用比特串行结构，Anda 的控制逻辑会带来约 18% 面积与 27% 功耗的额外开销。然而，一旦考虑到 Anda 能够根据实际精度要求缩短运算时间，其整体效率仍具有优势。

图 15(c)(d) 展示了在不同尾数配置下 Anda 的面积效率与能量效率。根据图 14 的结果，Anda 在 1% 精度约束下的典型尾数长度集中在 4–8 bit，因此相比 FIGNA，Anda 的面积效率与能量效率分别提升了约 1.38–2.48× 和 1.52–2.74×。在固定尾数长度下比较时，由于比特串行结构的控制开销，Anda 在 11 bit 时面积与能量效率分别比 FIGNA-M11 略低 12% 和 17%；在 8 bit 时分别比 FIGNA-M8 低 5% 与 15%。不过在系统层面，Anda 能根据模块与模型的精度要求灵活调整尾数，获得更高的利用率，这将在下一小节进一步分析。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/45d63d74fe904dd6f41051219c60b4f403cf32d15a8d28e1aadc0ae5bc2cbef7.jpg)

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/0b07e63e3c9ae281eebc97b6835fd70e1e8d959e143c1c1dc9dffdcb903ca362.jpg)

图 15. PE 级面积、功耗以及相应面积效率与能量效率对比。数据均归一化到 GPU 式 FP-FP PE。

## D. 系统级评估

图 16 比较了 Anda 与各类基线在不同 LLM 上的系统级 **加速比、面积效率和能量效率** 。我们也加入了 FIGNA-M11 与 FIGNA-M8 对应 0.1% 与 1% 精度约束下的基线作为参考。需要强调的是，Anda 仅需**一个统一硬件架构**便能支持精度可伸缩推理，而 FIGNA 对每种精度通常需要单独实现。

**加速比：**利用图 14 中搜索得到的精度组合，Anda 在 0.1% 精度约束下对 GPU 式 FP-FP 基线平均加速约 2.14×，在 1% 精度约束下平均加速约 2.49×。与同等精度损失下的 FIGNA 变体相比，Anda 分别获得约 1.48× 与 1.25× 的额外加速，源于其对不同张量采用了更灵活的尾数配置。

**面积效率：**在 0.1% 与 1% 精度约束下，Anda 对 FP-FP 基线的面积效率提升分别为约 3.47× 和 4.03×。这主要得益于：

(a) 共享指数大幅简化了对齐逻辑，提高了计算单元的面积利用率；

(b) 比特串行结构充分利用不同张量的尾数差异，实现更高的吞吐–面积比。

在 LLaMA 模型 1% 精度约束下，FIGNA-M8 在面积效率上与 Anda 接近甚至略有优势，这是因为固定 8 bit 尾数的比特并行结构在该点上极具竞争力。然而，Anda 可以在 OPT 模型中采用更激进尾数配置，从而在整体上获得更高的平均面积效率。

**能量效率：**在 0.1% 精度约束下，Anda 相比 FP-FP 基线的能量效率提升约 3.07×，在 1% 约束下提升约 3.16×。与仅从计算层面优化能量的 iFPU [42] 和 FIGNA [32] 不同，Anda 的比特串行架构通过跳过冗余尾数比特计算提高了单次运算的能量利用率，而 BPC 则通过压缩输出减少了内存访问能量。在 LLaMA-13B 模型上，图 17 进一步展示了能量分解：与 GPU 式 FP-FP 基线相比，Anda 在计算、SRAM 和 DRAM 三个部分的能量分别减少约 90%、54% 和 50%。虽然 FIGNA 在计算部分表现接近 Anda，但由于其需要频繁执行 FP 与 BFP 之间的转换，再加上仍采用 FP16 存储激活，其整体能量效率仍低于 Anda。相对 FIGNA，Anda 在 LLaMA-13B 上的 SRAM 与 DRAM 能量效率分别提升约 2.2× 与 2.0×。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/6fef167825bbce01661b5ba666077eee468e25ce9d730528e64c2573284ecc5a.jpg)

图 16. 在 WikiText2 上各加速器的加速比、面积效率与能量效率对比。所有数据归一化到 GPU 式 FP-FP 基线。

## E. 功耗与面积分解

我们以在 1% 精度损失下推理 LLaMA-13B 为例，对 Anda 的功耗和面积进行详细分解。表 III 给出了各组件的面积与功耗占比。在 285 MHz、0.8V 条件下，Anda 总面积约 2.17 mm²，总功耗约 81.18 mW。其中，作为核心计算单元的 MXU 占总面积的约 18.89%，却贡献了约 66.94% 的总功耗；BPC 虽承担了从全精度 FP 输出到 Anda 格式的在线压缩，但其面积与功耗仅占比分别为约 3.23% 与 1.31%。片上 SRAM 是面积主要来源，激活缓冲区和权重缓冲区分别占总面积的约 40.09% 与 36.87%，而对应功耗占比则为约 20.87% 与 9.81%，说明 Anda 在系统内部实现了较高的数据复用。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/c545286b594919b07471ccd26ef24876b9683c2b636447e0d5028aa4669cb721.jpg)

图 17. Anda 与基线加速器在 LLaMA-13B 推理时的能量分解。

TABLE III AREA AND POWER CHARACTERISTICS OF ANDA

## F. 精度–性能权衡

本节探讨在不同精度损失约束（0.1%–5%）下，Anda 相比 FP-FP 基线在加速比和能量效率上的提升。以 LLaMA-13B 为例，如图 18 所示，在仅 0.1% 精度损失约束下，Anda 即可获得约 1.73× 的加速比和 2.95× 的能量效率提升；当精度约束放宽至 5% 时，加速比与能量效率分别进一步提升到约 2.74× 与 3.22×。对各类模型而言，随着可接受精度损失增加，Anda 的性能与能效都呈持续提升趋势。

值得注意的是，OPT 与 LLaMA 系列在使用 Anda 时表现出不同的特征：由于 OPT 对尾数减少不太敏感，在较严格的精度约束（如 0.1%–0.5%）下，可以采用更短的尾数，从而获得比 LLaMA 更高的加速与能效；当精度约束逐渐放宽时，两者的性能提升开始趋于一致。通过将自适应精度组合搜索与 Anda 数据格式结合，我们的架构可以在不同的 LLM 与应用场景下灵活地在精度与性能之间进行调节，从而在多种部署环境中实现高效推理。

![](https://cdn-mineru.openxlab.org.cn/result/2025-12-10/9b4400b1-600b-4a47-ab72-be57b2407b86/368418815c739fb4e37d79ef436d1d6a1b6eff41f884ba95a2c266c7821898d8.jpg)

图 18. 在不同精度损失约束下，Anda 相对 FP-FP 基线的加速比与能量效率提升。

# VI. 相关工作与讨论

**比特串行与比特并行计算。**比特串行计算 [2], [7], [37], [46], [55], [68], [75] 在 DNN 加速领域已被广泛研究，其优势在于对可变精度的良好支持。但既有工作多聚焦于 INT 运算，因此难以直接应用于具有 FP 激活的 LLM。诸如 Bitlet [55] 与 Bitlet-X [7] 的方法探索了基于 FP 的比特串行计算，但由于其采用比特交织数据流，硬件和数据流设计较为复杂。相比之下，Anda 通过分组共享指数的方式简化了对齐开销，从而实现更简单高效的硬件设计。虽然比特串行方案在面积效率与时延方面通常不如比特并行 [41], [61], [67], [85]，但其在多精度可伸缩场景中具有更高的单元利用率。需要强调的是，Anda 的设计思想同样可以迁移到比特并行计算中，例如，我们的精度组合搜索方法可用于快速确定比特并行系统所需的最低精度配置，从而在保证精度的前提下提升效率。

**训练后量化（PTQ）与量化感知训练（QAT）。**量化是深度模型压缩的核心技术之一，通常分为 PTQ 与 QAT。对于 LLM，PTQ [24], [51], [66], [79] 更为主流，只需在单卡上用数小时便可得到精度较好的可部署模型；而 QAT [9], [21], [53], [74] 虽然潜在精度更高，但往往需要多卡集群以及上百小时训练，因此在实践中较少使用。Anda 采用 PTQ 路线，通过少量校准数据即可快速确定激活尾数长度，并可无缝集成到现有部署流水线中。未来工作可以探索将 Anda 扩展到 QAT 场景，进一步提升精度的同时，利用可变尾数降低训练开销。

**KV cache 优化。**在长上下文推理中，为了避免重复计算以往 token 的注意力，KV cache [82] 会在生成过程中缓存键和值，其大小随 token 数线性增长，因此在长序列场景中成为内存与速度瓶颈。已有工作从量化 [29], [54]、淘汰策略 [10], [88]、滑动窗口 [20], [80] 以及合并策略 [40], [87] 等方面提出了多种优化方案。Anda 主要针对 FP 激活的压缩，但可以与上述 KV cache 优化技术组合使用，从而在长上下文 LLM 推理中进一步提升性能与效率。

# VII. 结论

本文提出了  **Anda** ：一种可变长度分组激活数据格式，针对仅权重量化大语言模型（LLM）推理中因浮点激活冗余导致的能耗和性能瓶颈，给出了系统性的解决方案。我们通过分析不同模型及其内部模块对激活精度的敏感度，挖掘了浮点激活的冗余，并在此基础上提出了一种迭代式训练后精度分配算法，在模块级别优化尾数位宽，使模型精度、能效及推理速度之间达到平衡。我们进一步设计了与 Anda 格式深度协同的硬件优化，包括基于比特平面的存储组织、Anda 增强型比特串行处理单元以及运行时比特平面压缩器，共同在存储、计算与内存访问层面提升系统效率。

实验结果表明，相比 GPU 式 FP-FP 基线，Anda 在主流 LLM 的 FP-INT GeMM 运算上平均实现了  **2.4× 的加速、4.0× 的面积效率提升以及 3.1× 的能量效率提升** 。凭借对不同应用场景、精度需求与系统性能要求的良好适应性，Anda 为在资源受限环境中高效部署 LLM 提供了一条可行路径，有望推动大模型在更多实际场景中的广泛落地。
